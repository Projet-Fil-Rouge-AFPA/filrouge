{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "import pandas as pd\n",
    "import platform\n",
    "import pathlib\n",
    "import numpy as np\n",
    "from annotations import *\n",
    "from extract_video_features import *\n",
    "from extract_audio_features import *\n",
    "import cv2\n",
    "import seaborn as sns\n",
    "from scipy.stats import kurtosis, skew\n",
    "from sklearn.metrics import f1_score\n",
    "import importlib\n",
    "from tqdm import tqdm\n",
    "import ordinal_classification as o_c\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from util import runGridSearchClassifiers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get current directory\n",
    "cwd = os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'/Users/valentinadiproietto/filrouge'"
      ]
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "cwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "OpenFace_folder = '/Users/valentinadiproietto/OpenFace'\n",
    "filename_annotations = 'https://docs.google.com/spreadsheets/d/1Rqu1sJiD-ogc4a6R491JTiaYacptOTqh6DKqhwTa8NA/gviz/tq?tqx=out:csv&sheet=Template'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "Video_folder = '/Users/valentinadiproietto/Desktop/video_stress'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_paths, video_names = get_videos(Video_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['WIN_20210331_21_22_52_Pro',\n",
       " 'WIN_20210329_14_13_45_Pro',\n",
       " 'WIN_20210406_18_49_10_Pro',\n",
       " 'WIN_20210408_14_11_32_Pro',\n",
       " 'WIN_20210408_15_20_51_Pro',\n",
       " 'WIN_20210404_10_58_27_Pro',\n",
       " 'WIN_20210414_06_24_52_Pro',\n",
       " 'WIN_20210406_15_06_15_Pro',\n",
       " 'WIN_20210417_14_53_12_Pro',\n",
       " 'WIN_20210413_15_38_01_Pro',\n",
       " 'WIN_20210408_11_48_58_Pro',\n",
       " 'WIN_20210408_16_04_32_Pro',\n",
       " 'WIN_20210329_10_16_02_Pro',\n",
       " 'WIN_20210323_19_17_40_Pro',\n",
       " 'WIN_20210409_10_26_11_Pro',\n",
       " 'Test_pour_AFPA',\n",
       " 'WIN_20210405_15_09_16_Pro',\n",
       " 'WIN_20210407_14_54_56_Pro_edit2',\n",
       " 'WIN_20210406_21_05_52_Pro',\n",
       " 'WIN_20210403_18_49_15_Pro',\n",
       " 'WIN_20210408_14_02_19_Pro',\n",
       " 'WIN_20210415_15_41_24_Pro',\n",
       " 'WIN_20210406_18_35_52_Pro',\n",
       " 'WIN_20210402_14_27_50_Pro',\n",
       " 'WIN_20210407_09_04_05_Pro',\n",
       " 'WIN_20210402_19_04_53_Pro',\n",
       " 'WIN_20210416_08_06_54_Pro',\n",
       " 'Video_1',\n",
       " 'WIN_20210408_14_00_44_Pro',\n",
       " 'WIN_20210404_21_41_12_Pro',\n",
       " 'WIN_20210330_13_10_29_Pro']"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "video_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_dataframes = []\n",
    "for i in video_names: \n",
    "    list_dataframes.append(create_dataframe_video('/Users/valentinadiproietto/OpenFace/processed/', i))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_names.remove('WIN_20210329_14_13_45_Pro')\n",
    "video_names.remove('WIN_20210402_14_27_50_Pro')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "29"
      ]
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": [
    "len(video_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 29/29 [05:06<00:00, 10.57s/it]\n"
     ]
    }
   ],
   "source": [
    "list_df_max = []\n",
    "for v_name in tqdm(video_names):\n",
    "    df_annoted = get_df_video_with_annotations('/Users/valentinadiproietto/OpenFace/processed/', v_name, filename_annotations, \"max\")\n",
    "    list_df_max.append(eliminate_features(df_annoted))\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Index(['frame', 'face_id', 'timestamp', 'confidence', 'success', 'AU01_r',\n",
       "       'AU02_r', 'AU04_r', 'AU05_r', 'AU06_r', 'AU07_r', 'AU09_r', 'AU10_r',\n",
       "       'AU12_r', 'AU14_r', 'AU15_r', 'AU17_r', 'AU20_r', 'AU23_r', 'AU25_r',\n",
       "       'AU26_r', 'AU45_r', 'AU01_c', 'AU02_c', 'AU04_c', 'AU05_c', 'AU06_c',\n",
       "       'AU07_c', 'AU09_c', 'AU10_c', 'AU12_c', 'AU14_c', 'AU15_c', 'AU17_c',\n",
       "       'AU20_c', 'AU23_c', 'AU25_c', 'AU26_c', 'AU28_c', 'AU45_c', 'gaze_0_x',\n",
       "       'gaze_0_y', 'gaze_0_z', 'gaze_1_x', 'gaze_1_y', 'gaze_1_z',\n",
       "       'gaze_angle_x', 'gaze_angle_y', 'pose_Tx', 'pose_Ty', 'pose_Tz',\n",
       "       'pose_Rx', 'pose_Ry', 'pose_Rz', 'type_candidat', 'sexe', 'video_name',\n",
       "       'stress_global', 'stress', 'diapo'],\n",
       "      dtype='object')"
      ]
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "source": [
    "list_df_max[0].columns"
   ]
  },
  {
   "source": [
    "##"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## AGGREGATION TIME WINDOW AND FIRST RF ON TIME WINDOW %"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_with_deriv = []\n",
    "for i in list_df_max:\n",
    "    to_drop = ['frame','face_id','timestamp','confidence','success', 'type_candidat']\n",
    "    i = add_frameTimeWindow(i)\n",
    "    i = i.drop(to_drop, axis = 1)\n",
    "    i = add_derivatives_drop_spatial(i)\n",
    "    df_with_deriv.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "groupby_features= ['video_name','stress_global','stress','frameTimeWindow','sexe', 'diapo']\n",
    "\n",
    "df_total = pd.concat(df_with_deriv)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "stress\n",
       "1.0       2419\n",
       "0.0       2064\n",
       "2.0        638\n",
       "3.0         20\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 42
    }
   ],
   "source": [
    "df_total = df_total.groupby(groupby_features).agg(['mean']).reset_index()\n",
    "df_total.columns= df_total.columns.map('_'.join).str.strip('_')\n",
    "df_total[['stress']].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(5141, 99)"
      ]
     },
     "metadata": {},
     "execution_count": 44
    }
   ],
   "source": [
    "x = df_total.drop(['video_name','stress_global', 'stress','frameTimeWindow'], axis = 1)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(5141, 1)"
      ]
     },
     "metadata": {},
     "execution_count": 49
    }
   ],
   "source": [
    "#Replace string values\n",
    "x.sexe = x.sexe.replace('H',0)\n",
    "x.sexe = x.sexe.replace('F',1)\n",
    "\n",
    "y = df_total[['stress']]\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import LeaveOneGroupOut\n",
    "\n",
    "models_list = [RandomForestClassifier(random_state = 42, n_jobs=-1)]\n",
    "parameters_list = [\n",
    "                {'n_estimators': [100, 150, 200, 250, 300], 'max_depth':[10, 15, 20, 25,30], 'class_weight':[None,'balanced']}\n",
    "                ]\n",
    "groups = df_total['video_name']\n",
    "loo = LeaveOneGroupOut()\n",
    "cv_loo = loo.split(x, y, groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Fitting 29 folds for each of 50 candidates, totalling 1450 fits\n",
      "Best estimator RandomForestClassifier(class_weight='balanced', max_depth=10, n_estimators=200,\n",
      "                       n_jobs=-1, random_state=42)\n",
      "Best results 0.47420589324789425\n",
      "Best params {'class_weight': 'balanced', 'max_depth': 10, 'n_estimators': 200}\n",
      "accuracy (mean, std) 0.49188136107141134 0.18732930193915623\n",
      "f1 (mean, std) 0.47420589324789425 0.19976346176406967\n",
      "balanced accuracy (mean, std) 0.476389246580685 0.15440475243427615\n",
      "precision (mean, std) 0.6255117618166157 0.18639492327844862\n",
      "recall (mean, std) 0.49188136107141134 0.18732930193915623\n",
      "\n"
     ]
    }
   ],
   "source": [
    "best_result, y_predict, result_list = runGridSearchClassifiers(x, y, cv_loo, models_list, parameters_list, output_predict=True, n_jobs=-1, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving predictions\n",
    "predict5s = pd.concat([df_total[['video_name','diapo','frameTimeWindow']],\n",
    "                        pd.DataFrame(y_predict, columns=['ypredict'])],axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict5s.to_csv('all_features_tw5.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(5141, 99)"
      ]
     },
     "metadata": {},
     "execution_count": 54
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(5045, 1)"
      ]
     },
     "metadata": {},
     "execution_count": 40
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.6 64-bit ('base': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "interpreter": {
   "hash": "dd1cf4766d5d9df855e04619ca954236457012a0dce4d3d89890d807f4ecf8a5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}