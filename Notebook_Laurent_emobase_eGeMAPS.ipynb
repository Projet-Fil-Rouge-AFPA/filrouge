{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit ('base': conda)"
  },
  "metadata": {
   "interpreter": {
    "hash": "148f6ed9de8dadedbbd96ef8a7e818f87aaafab3c59f5306aa9910b4f09c5b3f"
   }
  },
  "interpreter": {
   "hash": "148f6ed9de8dadedbbd96ef8a7e818f87aaafab3c59f5306aa9910b4f09c5b3f"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt \n",
    "import pathlib\n",
    "from util import runGridSearchClassifiers"
   ]
  },
  {
   "source": [
    "## Loading data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory_path = '../../04_-_Dev/videos'\n",
    "#features = 'eGeMAPS'#'emobase'\n",
    "features1 = 'emobase'#''\n",
    "features2 = 'eGeMAPS'\n",
    "features = 'emobase_eGeMAPS'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_total_emobase = pd.read_pickle(directory_path + '/audio_' + features1 + '_data.p')\n",
    "df_total_eGeMaps = pd.read_pickle(directory_path + '/audio_' + features2 + '_data.p')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "((2573701, 60), (2573581, 77))"
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "df_total_emobase.shape, df_total_eGeMaps.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "WIN_20210409_10_26_11_Pro 1\n",
      "WIN_20210417_14_53_12_Pro 2\n",
      "WIN_20210330_13_10_29_Pro 3\n",
      "WIN_20210414_06_24_52_Pro 4\n",
      "Video_1 5\n",
      "Test_pour_AFPA 6\n",
      "WIN_20210408_14_02_19_Pro 7\n",
      "WIN_20210404_21_41_12_Pro 8\n",
      "WIN_20210415_15_41_24_Pro 9\n",
      "WIN_20210331_21_22_52_Pro 10\n",
      "WIN_20210407_14_54_56_Pro_edit2 11\n",
      "WIN_20210407_09_04_05_Pro 12\n",
      "WIN_20210329_10_16_02_Pro 13\n",
      "WIN_20210413_15_38_01_Pro 14\n",
      "WIN_20210323_19_17_40_Pro 15\n",
      "WIN_20210406_18_49_10_Pro 16\n",
      "WIN_20210402_19_04_53_Pro 17\n",
      "WIN_20210406_21_05_52_Pro 18\n",
      "WIN_20210408_16_04_32_Pro 19\n",
      "WIN_20210408_15_20_51_Pro 20\n",
      "WIN_20210402_14_27_50_Pro 21\n",
      "WIN_20210403_18_49_15_Pro 22\n",
      "WIN_20210408_14_00_44_Pro 23\n",
      "WIN_20210406_18_35_52_Pro 24\n",
      "WIN_20210408_11_48_58_Pro 25\n",
      "WIN_20210408_14_11_32_Pro 26\n",
      "WIN_20210404_10_58_27_Pro 27\n",
      "WIN_20210405_15_09_16_Pro 28\n",
      "WIN_20210406_15_06_15_Pro 29\n",
      "WIN_20210416_08_06_54_Pro 30\n",
      "Finished\n"
     ]
    }
   ],
   "source": [
    "video_name_list = df_total_emobase.video_name.unique()\n",
    "df_total = pd.DataFrame() \n",
    "i = 0\n",
    "for video_name in video_name_list:\n",
    "    i += 1\n",
    "    print(video_name, i)\n",
    "    df_total_emobase_temp = df_total_emobase.loc[df_total_emobase.video_name == video_name].iloc[:,:]\n",
    "    df_total_eGeMAPS_temp = df_total_eGeMaps.loc[df_total_eGeMaps.video_name == video_name].iloc[:,[1,3,4,5,6,7,12,13,14,15,16,17,18,19,20,21,22,23,24,27,29,31,33,35, 45,47,49,51,53,55,57,59,61,63,65,67,69,-6]]\n",
    "\n",
    "    df_total_temp = df_total_emobase_temp.merge(df_total_eGeMAPS_temp,how='inner', on=['video_name','frameTime'])\n",
    "    df_total = pd.concat([df_total,df_total_temp], axis=0)\n",
    "df_total.shape\n",
    "print('Finished')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                      video_name  stress_global type_candidat sexe  stress  \\\n",
       "0      WIN_20210409_10_26_11_Pro            0.0     Stagiaire    F     1.0   \n",
       "1      WIN_20210409_10_26_11_Pro            0.0     Stagiaire    F     1.0   \n",
       "2      WIN_20210409_10_26_11_Pro            0.0     Stagiaire    F     1.0   \n",
       "3      WIN_20210409_10_26_11_Pro            0.0     Stagiaire    F     1.0   \n",
       "4      WIN_20210409_10_26_11_Pro            0.0     Stagiaire    F     1.0   \n",
       "...                          ...            ...           ...  ...     ...   \n",
       "78135  WIN_20210416_08_06_54_Pro            1.0     Stagiaire    F     1.0   \n",
       "78136  WIN_20210416_08_06_54_Pro            1.0     Stagiaire    F     1.0   \n",
       "78137  WIN_20210416_08_06_54_Pro            1.0     Stagiaire    F     1.0   \n",
       "78138  WIN_20210416_08_06_54_Pro            1.0     Stagiaire    F     1.0   \n",
       "78139  WIN_20210416_08_06_54_Pro            1.0     Stagiaire    F     1.0   \n",
       "\n",
       "       diapo  \n",
       "0          1  \n",
       "1          1  \n",
       "2          1  \n",
       "3          1  \n",
       "4          1  \n",
       "...      ...  \n",
       "78135     18  \n",
       "78136     18  \n",
       "78137     18  \n",
       "78138     18  \n",
       "78139     18  \n",
       "\n",
       "[2573581 rows x 6 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>video_name</th>\n      <th>stress_global</th>\n      <th>type_candidat</th>\n      <th>sexe</th>\n      <th>stress</th>\n      <th>diapo</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>WIN_20210409_10_26_11_Pro</td>\n      <td>0.0</td>\n      <td>Stagiaire</td>\n      <td>F</td>\n      <td>1.0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>WIN_20210409_10_26_11_Pro</td>\n      <td>0.0</td>\n      <td>Stagiaire</td>\n      <td>F</td>\n      <td>1.0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>WIN_20210409_10_26_11_Pro</td>\n      <td>0.0</td>\n      <td>Stagiaire</td>\n      <td>F</td>\n      <td>1.0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>WIN_20210409_10_26_11_Pro</td>\n      <td>0.0</td>\n      <td>Stagiaire</td>\n      <td>F</td>\n      <td>1.0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>WIN_20210409_10_26_11_Pro</td>\n      <td>0.0</td>\n      <td>Stagiaire</td>\n      <td>F</td>\n      <td>1.0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>78135</th>\n      <td>WIN_20210416_08_06_54_Pro</td>\n      <td>1.0</td>\n      <td>Stagiaire</td>\n      <td>F</td>\n      <td>1.0</td>\n      <td>18</td>\n    </tr>\n    <tr>\n      <th>78136</th>\n      <td>WIN_20210416_08_06_54_Pro</td>\n      <td>1.0</td>\n      <td>Stagiaire</td>\n      <td>F</td>\n      <td>1.0</td>\n      <td>18</td>\n    </tr>\n    <tr>\n      <th>78137</th>\n      <td>WIN_20210416_08_06_54_Pro</td>\n      <td>1.0</td>\n      <td>Stagiaire</td>\n      <td>F</td>\n      <td>1.0</td>\n      <td>18</td>\n    </tr>\n    <tr>\n      <th>78138</th>\n      <td>WIN_20210416_08_06_54_Pro</td>\n      <td>1.0</td>\n      <td>Stagiaire</td>\n      <td>F</td>\n      <td>1.0</td>\n      <td>18</td>\n    </tr>\n    <tr>\n      <th>78139</th>\n      <td>WIN_20210416_08_06_54_Pro</td>\n      <td>1.0</td>\n      <td>Stagiaire</td>\n      <td>F</td>\n      <td>1.0</td>\n      <td>18</td>\n    </tr>\n  </tbody>\n</table>\n<p>2573581 rows × 6 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "df_total_annotations = df_total.iloc[:,54:60].copy()\n",
    "df_total_annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(2573581, 96)"
      ]
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "df_total = pd.concat([df_total.drop(df_total.columns[54:60], axis=1), df_total_annotations], axis=1)\n",
    "df_total.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_total = df_total.dropna(axis=0)\n",
    "df_total.to_pickle(directory_path + '/audio_' + features + '_data.p')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_total = pd.read_pickle(directory_path + '/audio_' + features + '_data.p')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "df_total.video_name.nunique() "
   ]
  },
  {
   "source": [
    "## Data pre-processing 1 - Sans utilisation de la temporalité"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "       frameIndex  frameTime  pcm_intensity_sma  pcm_loudness_sma  \\\n",
       "0               2       0.02       0.000000e+00          0.000000   \n",
       "1               3       0.03       0.000000e+00          0.000000   \n",
       "2               4       0.04       0.000000e+00          0.000000   \n",
       "3               5       0.05       0.000000e+00          0.000000   \n",
       "4               6       0.06       0.000000e+00          0.000000   \n",
       "...           ...        ...                ...               ...   \n",
       "78135       78137     781.37       7.011207e-12          0.027372   \n",
       "78136       78138     781.38       7.271935e-12          0.027709   \n",
       "78137       78139     781.39       8.054489e-12          0.029190   \n",
       "78138       78140     781.40       4.319410e-12          0.023441   \n",
       "78139       78141     781.41       3.975198e-12          0.022989   \n",
       "\n",
       "       mfcc_sma[1]  mfcc_sma[2]  mfcc_sma[3]  mfcc_sma[4]  mfcc_sma[5]  \\\n",
       "0        -5.952965     6.019684    -3.599674     1.358609    -0.693720   \n",
       "1        -4.113864     3.640915    -1.382292    -0.166187    -0.001379   \n",
       "2        -5.911817     5.975944    -3.576790     1.367325    -0.725028   \n",
       "3        -1.797952     2.335028    -2.194498     1.533511    -0.723649   \n",
       "4        -3.341751     4.400246    -4.248634     3.122386    -1.642255   \n",
       "...            ...          ...          ...          ...          ...   \n",
       "78135   -20.599420     3.417439    -2.851337     2.668345     1.097990   \n",
       "78136   -20.618000     3.963097    -2.573019     5.446637     3.623456   \n",
       "78137   -19.760860     6.082466    -2.668031     5.229023     3.715201   \n",
       "78138   -21.733470     5.059051    -2.391827     4.356356     5.255848   \n",
       "78139   -21.913380     3.731894    -4.589119     0.219700     1.376662   \n",
       "\n",
       "       mfcc_sma[6]  ...  F2frequency_sma3nz_de  F2amplitudeLogRelF0_sma3nz_de  \\\n",
       "0         0.796165  ...                 -0.271                            0.0   \n",
       "1         0.694905  ...                 -0.282                            0.0   \n",
       "2         0.827764  ...                 -0.008                            0.0   \n",
       "3         0.132860  ...                  0.271                            0.0   \n",
       "4         0.461863  ...                  0.299                            0.0   \n",
       "...            ...  ...                    ...                            ...   \n",
       "78135    -1.960824  ...                 37.419                            0.0   \n",
       "78136    -0.566356  ...                 -3.709                            0.0   \n",
       "78137    -1.398331  ...                 66.160                            0.0   \n",
       "78138    -0.879569  ...                -24.429                            0.0   \n",
       "78139    -5.050643  ...                 81.326                            0.0   \n",
       "\n",
       "       F3frequency_sma3nz_de  F3amplitudeLogRelF0_sma3nz_de  \\\n",
       "0                     -0.308                            0.0   \n",
       "1                     -0.400                            0.0   \n",
       "2                      0.091                            0.0   \n",
       "3                      0.362                            0.0   \n",
       "4                      0.288                            0.0   \n",
       "...                      ...                            ...   \n",
       "78135                -14.241                            0.0   \n",
       "78136                 -6.484                            0.0   \n",
       "78137                103.076                            0.0   \n",
       "78138                 30.289                            0.0   \n",
       "78139               -214.980                            0.0   \n",
       "\n",
       "                      video_name  stress_global  type_candidat  sexe  stress  \\\n",
       "0      WIN_20210409_10_26_11_Pro            0.0      Stagiaire     F     1.0   \n",
       "1      WIN_20210409_10_26_11_Pro            0.0      Stagiaire     F     1.0   \n",
       "2      WIN_20210409_10_26_11_Pro            0.0      Stagiaire     F     1.0   \n",
       "3      WIN_20210409_10_26_11_Pro            0.0      Stagiaire     F     1.0   \n",
       "4      WIN_20210409_10_26_11_Pro            0.0      Stagiaire     F     1.0   \n",
       "...                          ...            ...            ...   ...     ...   \n",
       "78135  WIN_20210416_08_06_54_Pro            1.0      Stagiaire     F     1.0   \n",
       "78136  WIN_20210416_08_06_54_Pro            1.0      Stagiaire     F     1.0   \n",
       "78137  WIN_20210416_08_06_54_Pro            1.0      Stagiaire     F     1.0   \n",
       "78138  WIN_20210416_08_06_54_Pro            1.0      Stagiaire     F     1.0   \n",
       "78139  WIN_20210416_08_06_54_Pro            1.0      Stagiaire     F     1.0   \n",
       "\n",
       "       diapo  \n",
       "0          1  \n",
       "1          1  \n",
       "2          1  \n",
       "3          1  \n",
       "4          1  \n",
       "...      ...  \n",
       "78135     18  \n",
       "78136     18  \n",
       "78137     18  \n",
       "78138     18  \n",
       "78139     18  \n",
       "\n",
       "[2573581 rows x 96 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>frameIndex</th>\n      <th>frameTime</th>\n      <th>pcm_intensity_sma</th>\n      <th>pcm_loudness_sma</th>\n      <th>mfcc_sma[1]</th>\n      <th>mfcc_sma[2]</th>\n      <th>mfcc_sma[3]</th>\n      <th>mfcc_sma[4]</th>\n      <th>mfcc_sma[5]</th>\n      <th>mfcc_sma[6]</th>\n      <th>...</th>\n      <th>F2frequency_sma3nz_de</th>\n      <th>F2amplitudeLogRelF0_sma3nz_de</th>\n      <th>F3frequency_sma3nz_de</th>\n      <th>F3amplitudeLogRelF0_sma3nz_de</th>\n      <th>video_name</th>\n      <th>stress_global</th>\n      <th>type_candidat</th>\n      <th>sexe</th>\n      <th>stress</th>\n      <th>diapo</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2</td>\n      <td>0.02</td>\n      <td>0.000000e+00</td>\n      <td>0.000000</td>\n      <td>-5.952965</td>\n      <td>6.019684</td>\n      <td>-3.599674</td>\n      <td>1.358609</td>\n      <td>-0.693720</td>\n      <td>0.796165</td>\n      <td>...</td>\n      <td>-0.271</td>\n      <td>0.0</td>\n      <td>-0.308</td>\n      <td>0.0</td>\n      <td>WIN_20210409_10_26_11_Pro</td>\n      <td>0.0</td>\n      <td>Stagiaire</td>\n      <td>F</td>\n      <td>1.0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>3</td>\n      <td>0.03</td>\n      <td>0.000000e+00</td>\n      <td>0.000000</td>\n      <td>-4.113864</td>\n      <td>3.640915</td>\n      <td>-1.382292</td>\n      <td>-0.166187</td>\n      <td>-0.001379</td>\n      <td>0.694905</td>\n      <td>...</td>\n      <td>-0.282</td>\n      <td>0.0</td>\n      <td>-0.400</td>\n      <td>0.0</td>\n      <td>WIN_20210409_10_26_11_Pro</td>\n      <td>0.0</td>\n      <td>Stagiaire</td>\n      <td>F</td>\n      <td>1.0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>4</td>\n      <td>0.04</td>\n      <td>0.000000e+00</td>\n      <td>0.000000</td>\n      <td>-5.911817</td>\n      <td>5.975944</td>\n      <td>-3.576790</td>\n      <td>1.367325</td>\n      <td>-0.725028</td>\n      <td>0.827764</td>\n      <td>...</td>\n      <td>-0.008</td>\n      <td>0.0</td>\n      <td>0.091</td>\n      <td>0.0</td>\n      <td>WIN_20210409_10_26_11_Pro</td>\n      <td>0.0</td>\n      <td>Stagiaire</td>\n      <td>F</td>\n      <td>1.0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>5</td>\n      <td>0.05</td>\n      <td>0.000000e+00</td>\n      <td>0.000000</td>\n      <td>-1.797952</td>\n      <td>2.335028</td>\n      <td>-2.194498</td>\n      <td>1.533511</td>\n      <td>-0.723649</td>\n      <td>0.132860</td>\n      <td>...</td>\n      <td>0.271</td>\n      <td>0.0</td>\n      <td>0.362</td>\n      <td>0.0</td>\n      <td>WIN_20210409_10_26_11_Pro</td>\n      <td>0.0</td>\n      <td>Stagiaire</td>\n      <td>F</td>\n      <td>1.0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>6</td>\n      <td>0.06</td>\n      <td>0.000000e+00</td>\n      <td>0.000000</td>\n      <td>-3.341751</td>\n      <td>4.400246</td>\n      <td>-4.248634</td>\n      <td>3.122386</td>\n      <td>-1.642255</td>\n      <td>0.461863</td>\n      <td>...</td>\n      <td>0.299</td>\n      <td>0.0</td>\n      <td>0.288</td>\n      <td>0.0</td>\n      <td>WIN_20210409_10_26_11_Pro</td>\n      <td>0.0</td>\n      <td>Stagiaire</td>\n      <td>F</td>\n      <td>1.0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>78135</th>\n      <td>78137</td>\n      <td>781.37</td>\n      <td>7.011207e-12</td>\n      <td>0.027372</td>\n      <td>-20.599420</td>\n      <td>3.417439</td>\n      <td>-2.851337</td>\n      <td>2.668345</td>\n      <td>1.097990</td>\n      <td>-1.960824</td>\n      <td>...</td>\n      <td>37.419</td>\n      <td>0.0</td>\n      <td>-14.241</td>\n      <td>0.0</td>\n      <td>WIN_20210416_08_06_54_Pro</td>\n      <td>1.0</td>\n      <td>Stagiaire</td>\n      <td>F</td>\n      <td>1.0</td>\n      <td>18</td>\n    </tr>\n    <tr>\n      <th>78136</th>\n      <td>78138</td>\n      <td>781.38</td>\n      <td>7.271935e-12</td>\n      <td>0.027709</td>\n      <td>-20.618000</td>\n      <td>3.963097</td>\n      <td>-2.573019</td>\n      <td>5.446637</td>\n      <td>3.623456</td>\n      <td>-0.566356</td>\n      <td>...</td>\n      <td>-3.709</td>\n      <td>0.0</td>\n      <td>-6.484</td>\n      <td>0.0</td>\n      <td>WIN_20210416_08_06_54_Pro</td>\n      <td>1.0</td>\n      <td>Stagiaire</td>\n      <td>F</td>\n      <td>1.0</td>\n      <td>18</td>\n    </tr>\n    <tr>\n      <th>78137</th>\n      <td>78139</td>\n      <td>781.39</td>\n      <td>8.054489e-12</td>\n      <td>0.029190</td>\n      <td>-19.760860</td>\n      <td>6.082466</td>\n      <td>-2.668031</td>\n      <td>5.229023</td>\n      <td>3.715201</td>\n      <td>-1.398331</td>\n      <td>...</td>\n      <td>66.160</td>\n      <td>0.0</td>\n      <td>103.076</td>\n      <td>0.0</td>\n      <td>WIN_20210416_08_06_54_Pro</td>\n      <td>1.0</td>\n      <td>Stagiaire</td>\n      <td>F</td>\n      <td>1.0</td>\n      <td>18</td>\n    </tr>\n    <tr>\n      <th>78138</th>\n      <td>78140</td>\n      <td>781.40</td>\n      <td>4.319410e-12</td>\n      <td>0.023441</td>\n      <td>-21.733470</td>\n      <td>5.059051</td>\n      <td>-2.391827</td>\n      <td>4.356356</td>\n      <td>5.255848</td>\n      <td>-0.879569</td>\n      <td>...</td>\n      <td>-24.429</td>\n      <td>0.0</td>\n      <td>30.289</td>\n      <td>0.0</td>\n      <td>WIN_20210416_08_06_54_Pro</td>\n      <td>1.0</td>\n      <td>Stagiaire</td>\n      <td>F</td>\n      <td>1.0</td>\n      <td>18</td>\n    </tr>\n    <tr>\n      <th>78139</th>\n      <td>78141</td>\n      <td>781.41</td>\n      <td>3.975198e-12</td>\n      <td>0.022989</td>\n      <td>-21.913380</td>\n      <td>3.731894</td>\n      <td>-4.589119</td>\n      <td>0.219700</td>\n      <td>1.376662</td>\n      <td>-5.050643</td>\n      <td>...</td>\n      <td>81.326</td>\n      <td>0.0</td>\n      <td>-214.980</td>\n      <td>0.0</td>\n      <td>WIN_20210416_08_06_54_Pro</td>\n      <td>1.0</td>\n      <td>Stagiaire</td>\n      <td>F</td>\n      <td>1.0</td>\n      <td>18</td>\n    </tr>\n  </tbody>\n</table>\n<p>2573581 rows × 96 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "df_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import kurtosis, skew\n",
    "\n",
    "def percentil25(x): \n",
    "    return np.percentile(x, q=25)\n",
    "\n",
    "def percentil75(x): \n",
    "    return np.percentile(x, q=75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sequence as a whole with 9 agregators\n",
    "X = df_total.iloc[:,2:].groupby(['video_name','diapo']).agg({'mean','min','max', 'median', 'std', percentil25, percentil75, kurtosis, skew}).iloc[:,:-18]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sequence as a whole with 4 agregators\n",
    "#X = df_total.iloc[:,2:].groupby(['video_name','diapo']).agg({'mean','std', kurtosis, skew}).iloc[:,:-8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(240, 792)"
      ]
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                pcm_intensity_sma                              \\\n",
       "                                         kurtosis   percentil75          mean   \n",
       "video_name                diapo                                                 \n",
       "Test_pour_AFPA            1           3146.853019  1.225298e-10  1.138096e-08   \n",
       "                          8            123.403605  1.725128e-07  3.445894e-07   \n",
       "                          9            806.978682  1.095324e-07  2.626492e-07   \n",
       "                          10           796.376223  9.802079e-08  2.443886e-07   \n",
       "                          11           827.561300  1.422769e-07  2.895271e-07   \n",
       "...                                           ...           ...           ...   \n",
       "WIN_20210417_14_53_12_Pro 10            57.749166  6.072907e-08  1.405645e-07   \n",
       "                          11            38.423855  1.018110e-07  1.452637e-07   \n",
       "                          12           151.489483  2.517556e-11  9.356331e-11   \n",
       "                          17            28.893323  3.321533e-07  3.458074e-07   \n",
       "                          18          1138.886704  3.486819e-11  4.188208e-11   \n",
       "\n",
       "                                                                           \\\n",
       "                                       median           std   percentil25   \n",
       "video_name                diapo                                             \n",
       "Test_pour_AFPA            1      6.973609e-11  2.748632e-07  3.819657e-11   \n",
       "                          8      1.126761e-08  1.159030e-06  7.489974e-11   \n",
       "                          9      2.440317e-09  1.142409e-06  6.744114e-11   \n",
       "                          10     7.152661e-10  1.367874e-06  5.894842e-11   \n",
       "                          11     5.700818e-09  1.446588e-06  7.155228e-11   \n",
       "...                                       ...           ...           ...   \n",
       "WIN_20210417_14_53_12_Pro 10     2.086603e-13  4.197754e-07  0.000000e+00   \n",
       "                          11     6.047051e-11  3.674674e-07  0.000000e+00   \n",
       "                          12     2.128377e-12  3.760241e-10  1.669329e-13   \n",
       "                          17     2.809062e-08  7.997970e-07  4.173518e-14   \n",
       "                          18     3.088259e-12  2.102343e-10  0.000000e+00   \n",
       "\n",
       "                                                                        \\\n",
       "                                          max       skew           min   \n",
       "video_name                diapo                                          \n",
       "Test_pour_AFPA            1      1.795643e-05  52.102370  3.338736e-13   \n",
       "                          8      2.552147e-05   8.773747  2.629277e-12   \n",
       "                          9      4.923681e-05  21.745491  1.293720e-12   \n",
       "                          10     5.260212e-05  23.775476  1.544100e-12   \n",
       "                          11     6.543399e-05  23.492521  8.346372e-13   \n",
       "...                                       ...        ...           ...   \n",
       "WIN_20210417_14_53_12_Pro 10     6.300619e-06   6.260282  0.000000e+00   \n",
       "                          11     5.826240e-06   4.954644  0.000000e+00   \n",
       "                          12     9.125553e-09  10.185306  0.000000e+00   \n",
       "                          17     8.491340e-06   4.658821  0.000000e+00   \n",
       "                          18     1.093041e-08  28.082202  0.000000e+00   \n",
       "\n",
       "                                pcm_loudness_sma  ... F3frequency_sma3nz_de  \\\n",
       "                                        kurtosis  ...                   min   \n",
       "video_name                diapo                   ...                         \n",
       "Test_pour_AFPA            1           110.605648  ...              -636.236   \n",
       "                          8             2.449132  ...              -746.555   \n",
       "                          9             3.356419  ...              -772.766   \n",
       "                          10            6.276675  ...              -809.146   \n",
       "                          11            4.856575  ...              -604.733   \n",
       "...                                          ...  ...                   ...   \n",
       "WIN_20210417_14_53_12_Pro 10            1.557186  ...             -3463.501   \n",
       "                          11            0.392474  ...             -3206.950   \n",
       "                          12            4.143871  ...             -3415.453   \n",
       "                          17           -0.064135  ...             -2745.664   \n",
       "                          18            2.431557  ...             -3318.522   \n",
       "\n",
       "                                F3amplitudeLogRelF0_sma3nz_de              \\\n",
       "                                                     kurtosis percentil75   \n",
       "video_name                diapo                                             \n",
       "Test_pour_AFPA            1                         52.685368    0.000000   \n",
       "                          8                          7.024527    0.623615   \n",
       "                          9                          7.933254    0.171658   \n",
       "                          10                         9.481523    0.009555   \n",
       "                          11                         7.993915    0.450117   \n",
       "...                                                       ...         ...   \n",
       "WIN_20210417_14_53_12_Pro 10                        14.613806    0.000000   \n",
       "                          11                         7.463822    0.000000   \n",
       "                          12                        40.721230    0.000000   \n",
       "                          17                         7.682969    0.973517   \n",
       "                          18                       197.205709    0.000000   \n",
       "\n",
       "                                                                             \\\n",
       "                                         mean median        std percentil25   \n",
       "video_name                diapo                                               \n",
       "Test_pour_AFPA            1     -2.006474e-17    0.0   8.169169    0.000000   \n",
       "                          8      9.094947e-17    0.0  20.884722   -0.584045   \n",
       "                          9     -5.454672e-17    0.0  19.601881   -0.183262   \n",
       "                          10     1.730266e-02    0.0  18.050512   -0.023468   \n",
       "                          11    -1.207582e-02    0.0  19.650910   -0.416281   \n",
       "...                                       ...    ...        ...         ...   \n",
       "WIN_20210417_14_53_12_Pro 10    -8.484092e-17    0.0  16.756632    0.000000   \n",
       "                          11     3.700743e-17    0.0  19.816427    0.000000   \n",
       "                          12     3.442381e-17    0.0   8.894117    0.000000   \n",
       "                          17    -1.886613e-16    0.0  19.742638   -1.185110   \n",
       "                          18     6.431415e-19    0.0   4.184147    0.000000   \n",
       "\n",
       "                                                                \n",
       "                                       max      skew       min  \n",
       "video_name                diapo                                 \n",
       "Test_pour_AFPA            1       70.25570  0.251677 -68.80670  \n",
       "                          8       83.30572 -0.016638 -84.51590  \n",
       "                          9       83.64715  0.006842 -82.88608  \n",
       "                          10      83.24970  0.015493 -83.92216  \n",
       "                          11     104.70520  0.037084 -85.56730  \n",
       "...                                    ...       ...       ...  \n",
       "WIN_20210417_14_53_12_Pro 10     201.00000  0.587303 -94.94055  \n",
       "                          11      86.81973  0.152838 -81.30158  \n",
       "                          12      72.95508  0.023611 -72.95505  \n",
       "                          17      85.33570  0.003491 -83.99115  \n",
       "                          18      67.28460 -0.215763 -66.82085  \n",
       "\n",
       "[240 rows x 792 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead tr th {\n        text-align: left;\n    }\n\n    .dataframe thead tr:last-of-type th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr>\n      <th></th>\n      <th></th>\n      <th colspan=\"9\" halign=\"left\">pcm_intensity_sma</th>\n      <th>pcm_loudness_sma</th>\n      <th>...</th>\n      <th>F3frequency_sma3nz_de</th>\n      <th colspan=\"9\" halign=\"left\">F3amplitudeLogRelF0_sma3nz_de</th>\n    </tr>\n    <tr>\n      <th></th>\n      <th></th>\n      <th>kurtosis</th>\n      <th>percentil75</th>\n      <th>mean</th>\n      <th>median</th>\n      <th>std</th>\n      <th>percentil25</th>\n      <th>max</th>\n      <th>skew</th>\n      <th>min</th>\n      <th>kurtosis</th>\n      <th>...</th>\n      <th>min</th>\n      <th>kurtosis</th>\n      <th>percentil75</th>\n      <th>mean</th>\n      <th>median</th>\n      <th>std</th>\n      <th>percentil25</th>\n      <th>max</th>\n      <th>skew</th>\n      <th>min</th>\n    </tr>\n    <tr>\n      <th>video_name</th>\n      <th>diapo</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th rowspan=\"5\" valign=\"top\">Test_pour_AFPA</th>\n      <th>1</th>\n      <td>3146.853019</td>\n      <td>1.225298e-10</td>\n      <td>1.138096e-08</td>\n      <td>6.973609e-11</td>\n      <td>2.748632e-07</td>\n      <td>3.819657e-11</td>\n      <td>1.795643e-05</td>\n      <td>52.102370</td>\n      <td>3.338736e-13</td>\n      <td>110.605648</td>\n      <td>...</td>\n      <td>-636.236</td>\n      <td>52.685368</td>\n      <td>0.000000</td>\n      <td>-2.006474e-17</td>\n      <td>0.0</td>\n      <td>8.169169</td>\n      <td>0.000000</td>\n      <td>70.25570</td>\n      <td>0.251677</td>\n      <td>-68.80670</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>123.403605</td>\n      <td>1.725128e-07</td>\n      <td>3.445894e-07</td>\n      <td>1.126761e-08</td>\n      <td>1.159030e-06</td>\n      <td>7.489974e-11</td>\n      <td>2.552147e-05</td>\n      <td>8.773747</td>\n      <td>2.629277e-12</td>\n      <td>2.449132</td>\n      <td>...</td>\n      <td>-746.555</td>\n      <td>7.024527</td>\n      <td>0.623615</td>\n      <td>9.094947e-17</td>\n      <td>0.0</td>\n      <td>20.884722</td>\n      <td>-0.584045</td>\n      <td>83.30572</td>\n      <td>-0.016638</td>\n      <td>-84.51590</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>806.978682</td>\n      <td>1.095324e-07</td>\n      <td>2.626492e-07</td>\n      <td>2.440317e-09</td>\n      <td>1.142409e-06</td>\n      <td>6.744114e-11</td>\n      <td>4.923681e-05</td>\n      <td>21.745491</td>\n      <td>1.293720e-12</td>\n      <td>3.356419</td>\n      <td>...</td>\n      <td>-772.766</td>\n      <td>7.933254</td>\n      <td>0.171658</td>\n      <td>-5.454672e-17</td>\n      <td>0.0</td>\n      <td>19.601881</td>\n      <td>-0.183262</td>\n      <td>83.64715</td>\n      <td>0.006842</td>\n      <td>-82.88608</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>796.376223</td>\n      <td>9.802079e-08</td>\n      <td>2.443886e-07</td>\n      <td>7.152661e-10</td>\n      <td>1.367874e-06</td>\n      <td>5.894842e-11</td>\n      <td>5.260212e-05</td>\n      <td>23.775476</td>\n      <td>1.544100e-12</td>\n      <td>6.276675</td>\n      <td>...</td>\n      <td>-809.146</td>\n      <td>9.481523</td>\n      <td>0.009555</td>\n      <td>1.730266e-02</td>\n      <td>0.0</td>\n      <td>18.050512</td>\n      <td>-0.023468</td>\n      <td>83.24970</td>\n      <td>0.015493</td>\n      <td>-83.92216</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>827.561300</td>\n      <td>1.422769e-07</td>\n      <td>2.895271e-07</td>\n      <td>5.700818e-09</td>\n      <td>1.446588e-06</td>\n      <td>7.155228e-11</td>\n      <td>6.543399e-05</td>\n      <td>23.492521</td>\n      <td>8.346372e-13</td>\n      <td>4.856575</td>\n      <td>...</td>\n      <td>-604.733</td>\n      <td>7.993915</td>\n      <td>0.450117</td>\n      <td>-1.207582e-02</td>\n      <td>0.0</td>\n      <td>19.650910</td>\n      <td>-0.416281</td>\n      <td>104.70520</td>\n      <td>0.037084</td>\n      <td>-85.56730</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th rowspan=\"5\" valign=\"top\">WIN_20210417_14_53_12_Pro</th>\n      <th>10</th>\n      <td>57.749166</td>\n      <td>6.072907e-08</td>\n      <td>1.405645e-07</td>\n      <td>2.086603e-13</td>\n      <td>4.197754e-07</td>\n      <td>0.000000e+00</td>\n      <td>6.300619e-06</td>\n      <td>6.260282</td>\n      <td>0.000000e+00</td>\n      <td>1.557186</td>\n      <td>...</td>\n      <td>-3463.501</td>\n      <td>14.613806</td>\n      <td>0.000000</td>\n      <td>-8.484092e-17</td>\n      <td>0.0</td>\n      <td>16.756632</td>\n      <td>0.000000</td>\n      <td>201.00000</td>\n      <td>0.587303</td>\n      <td>-94.94055</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>38.423855</td>\n      <td>1.018110e-07</td>\n      <td>1.452637e-07</td>\n      <td>6.047051e-11</td>\n      <td>3.674674e-07</td>\n      <td>0.000000e+00</td>\n      <td>5.826240e-06</td>\n      <td>4.954644</td>\n      <td>0.000000e+00</td>\n      <td>0.392474</td>\n      <td>...</td>\n      <td>-3206.950</td>\n      <td>7.463822</td>\n      <td>0.000000</td>\n      <td>3.700743e-17</td>\n      <td>0.0</td>\n      <td>19.816427</td>\n      <td>0.000000</td>\n      <td>86.81973</td>\n      <td>0.152838</td>\n      <td>-81.30158</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>151.489483</td>\n      <td>2.517556e-11</td>\n      <td>9.356331e-11</td>\n      <td>2.128377e-12</td>\n      <td>3.760241e-10</td>\n      <td>1.669329e-13</td>\n      <td>9.125553e-09</td>\n      <td>10.185306</td>\n      <td>0.000000e+00</td>\n      <td>4.143871</td>\n      <td>...</td>\n      <td>-3415.453</td>\n      <td>40.721230</td>\n      <td>0.000000</td>\n      <td>3.442381e-17</td>\n      <td>0.0</td>\n      <td>8.894117</td>\n      <td>0.000000</td>\n      <td>72.95508</td>\n      <td>0.023611</td>\n      <td>-72.95505</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>28.893323</td>\n      <td>3.321533e-07</td>\n      <td>3.458074e-07</td>\n      <td>2.809062e-08</td>\n      <td>7.997970e-07</td>\n      <td>4.173518e-14</td>\n      <td>8.491340e-06</td>\n      <td>4.658821</td>\n      <td>0.000000e+00</td>\n      <td>-0.064135</td>\n      <td>...</td>\n      <td>-2745.664</td>\n      <td>7.682969</td>\n      <td>0.973517</td>\n      <td>-1.886613e-16</td>\n      <td>0.0</td>\n      <td>19.742638</td>\n      <td>-1.185110</td>\n      <td>85.33570</td>\n      <td>0.003491</td>\n      <td>-83.99115</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>1138.886704</td>\n      <td>3.486819e-11</td>\n      <td>4.188208e-11</td>\n      <td>3.088259e-12</td>\n      <td>2.102343e-10</td>\n      <td>0.000000e+00</td>\n      <td>1.093041e-08</td>\n      <td>28.082202</td>\n      <td>0.000000e+00</td>\n      <td>2.431557</td>\n      <td>...</td>\n      <td>-3318.522</td>\n      <td>197.205709</td>\n      <td>0.000000</td>\n      <td>6.431415e-19</td>\n      <td>0.0</td>\n      <td>4.184147</td>\n      <td>0.000000</td>\n      <td>67.28460</td>\n      <td>-0.215763</td>\n      <td>-66.82085</td>\n    </tr>\n  </tbody>\n</table>\n<p>240 rows × 792 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_temp = df_total[['video_name','diapo','type_candidat','sexe']].groupby(['video_name','diapo']).agg({'type_candidat':'first','sexe':'first'})\n",
    "X_temp.loc[X_temp['type_candidat'] == 'Stagiaire','Stagiaire'] = 1\n",
    "X_temp.loc[X_temp['type_candidat'] != 'Stagiaire','Stagiaire'] = 0\n",
    "X_temp.loc[X_temp['sexe'] == 'F','Femme'] = 1\n",
    "X_temp.loc[X_temp['sexe'] != 'F','Femme'] = 0\n",
    "X_temp = X_temp.drop(['type_candidat','sexe'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.concat([X,X_temp],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df_total.iloc[:,2:].groupby(['video_name','diapo']).agg({'stress':'mean'}).iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "((240, 794), (240,))"
      ]
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "source": [
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.to_pickle(directory_path + '/audio_' + features + '_data_X.p')\n",
    "y.to_pickle(directory_path + '/audio_' + features + '_data_y.p')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import kurtosis, skew\n",
    "X_audio = df_total.loc[df_total['diapo'].isin([8, 9, 10, 11, 17]),:].iloc[:,2:].groupby(['video_name','diapo']).agg({'mean','min','max', 'median', 'std', percentil25, percentil75, kurtosis, skew}).iloc[:,:-18]\n",
    "y_audio = df_total.loc[df_total['diapo'].isin([8, 9, 10, 11, 17]),:].iloc[:,2:].groupby(['video_name','diapo']).agg({'stress':'mean'}).iloc[:,-1]\n",
    "\n",
    "X_audio.to_pickle(directory_path + '/audio_' + features + '_data_X_audio.p')\n",
    "y_audio.to_pickle(directory_path + '/audio_' + features + '_data_y_audio.p')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(150, 792)"
      ]
     },
     "metadata": {},
     "execution_count": 18
    }
   ],
   "source": [
    "X_audio.shape"
   ]
  },
  {
   "source": [
    "## Modèles"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.read_pickle(directory_path + '/audio_' + features + '_data_X.p')\n",
    "y = pd.read_pickle(directory_path + '/audio_' + features + '_data_y.p')\n",
    "\n",
    "X_audio = pd.read_pickle(directory_path + '/audio_' + features + '_data_X_audio.p')\n",
    "y_audio = pd.read_pickle(directory_path + '/audio_' + features + '_data_y_audio.p')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "((240, 794), (150, 792))"
      ]
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "X.shape, X_audio.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "source": [
    "### Leave one interview out\n",
    "#### All diapos"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "diapo_selection = '_all'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import LeaveOneGroupOut\n",
    "\n",
    "models_list = [RandomForestClassifier(random_state = 42, n_jobs=-1)]\n",
    "parameters_list = [\n",
    "                {'n_estimators': [50, 100, 150, 200], 'max_depth':[3, 4, 5, 6, 10, 15, 20, 25], 'class_weight':[None,'balanced']}\n",
    "                ]\n",
    "groups = X.reset_index()['video_name']\n",
    "loo = LeaveOneGroupOut()\n",
    "cv_loo = loo.split(X, y, groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Fitting 30 folds for each of 64 candidates, totalling 1920 fits\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    3.9s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:   18.2s\n",
      "[Parallel(n_jobs=-1)]: Done 434 tasks      | elapsed:   44.5s\n",
      "[Parallel(n_jobs=-1)]: Done 784 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=-1)]: Done 1234 tasks      | elapsed:  2.4min\n",
      "[Parallel(n_jobs=-1)]: Done 1784 tasks      | elapsed:  3.5min\n",
      "[Parallel(n_jobs=-1)]: Done 1920 out of 1920 | elapsed:  3.8min finished\n",
      "Best estimator RandomForestClassifier(class_weight='balanced', max_depth=20, n_estimators=50,\n",
      "                       n_jobs=-1, random_state=42)\n",
      "Best results 0.48623413623413625\n",
      "Best params {'class_weight': 'balanced', 'max_depth': 20, 'n_estimators': 50}\n",
      "accuracy (mean, std) 0.49166666666666664 0.20395397084200695\n",
      "f1 (mean, std) 0.48623413623413625 0.21334018689876427\n",
      "balanced accuracy (mean, std) 0.47874338624338625 0.23125030065949675\n",
      "precision (mean, std) 0.5930406746031746 0.2861846164029956\n",
      "recall (mean, std) 0.49166666666666664 0.20395397084200695\n",
      "\n",
      "f1_score (weighted) 0.45709993011879807\n",
      "accuracy 0.49166666666666664\n"
     ]
    }
   ],
   "source": [
    "best_result, y_predict, y_predict_proba, result_list = runGridSearchClassifiers(X, y, cv_loo, models_list, parameters_list, \n",
    "                                                                output_predict=True, n_jobs=-1, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving predictions\n",
    "df_ypredict = pd.concat([X.reset_index()[['video_name','diapo']],pd.DataFrame(y_predict, columns=['ypredict'])],axis=1)\n",
    "df_ypredict.to_csv('ypredict_' + features + '_diapo' + diapo_selection + '.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                    video_name  diapo  ypredict\n",
       "0               Test_pour_AFPA      1       1.0\n",
       "1               Test_pour_AFPA      8       1.0\n",
       "2               Test_pour_AFPA      9       1.0\n",
       "3               Test_pour_AFPA     10       1.0\n",
       "4               Test_pour_AFPA     11       1.0\n",
       "..                         ...    ...       ...\n",
       "235  WIN_20210417_14_53_12_Pro     10       1.0\n",
       "236  WIN_20210417_14_53_12_Pro     11       1.0\n",
       "237  WIN_20210417_14_53_12_Pro     12       1.0\n",
       "238  WIN_20210417_14_53_12_Pro     17       0.0\n",
       "239  WIN_20210417_14_53_12_Pro     18       0.0\n",
       "\n",
       "[240 rows x 3 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>video_name</th>\n      <th>diapo</th>\n      <th>ypredict</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Test_pour_AFPA</td>\n      <td>1</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Test_pour_AFPA</td>\n      <td>8</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Test_pour_AFPA</td>\n      <td>9</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Test_pour_AFPA</td>\n      <td>10</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Test_pour_AFPA</td>\n      <td>11</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>235</th>\n      <td>WIN_20210417_14_53_12_Pro</td>\n      <td>10</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>236</th>\n      <td>WIN_20210417_14_53_12_Pro</td>\n      <td>11</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>237</th>\n      <td>WIN_20210417_14_53_12_Pro</td>\n      <td>12</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>238</th>\n      <td>WIN_20210417_14_53_12_Pro</td>\n      <td>17</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>239</th>\n      <td>WIN_20210417_14_53_12_Pro</td>\n      <td>18</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>240 rows × 3 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "source": [
    "df_ypredict\n",
    "#len(y_predict)"
   ]
  },
  {
   "source": [
    "### Audio diapos only"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "diapo_selection = '_audio_only'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import LeaveOneGroupOut\n",
    "\n",
    "models_list = [RandomForestClassifier(random_state = 42, n_jobs=-1)]\n",
    "parameters_list = [\n",
    "                {'n_estimators': [50, 100, 150, 200], 'max_depth':[3, 4, 5, 6,7 ,8,9, 10, 15, 20, 25], 'class_weight':[None,'balanced']}\n",
    "                ]\n",
    "groups = X_audio.reset_index()['video_name']\n",
    "loo = LeaveOneGroupOut()\n",
    "cv_loo = loo.split(X_audio, y_audio, groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Fitting 30 folds for each of 88 candidates, totalling 2640 fits\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    2.3s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:   16.1s\n",
      "[Parallel(n_jobs=-1)]: Done 434 tasks      | elapsed:   41.8s\n",
      "[Parallel(n_jobs=-1)]: Done 784 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done 1234 tasks      | elapsed:  2.1min\n",
      "[Parallel(n_jobs=-1)]: Done 1784 tasks      | elapsed:  3.0min\n",
      "[Parallel(n_jobs=-1)]: Done 2434 tasks      | elapsed:  4.2min\n",
      "[Parallel(n_jobs=-1)]: Done 2640 out of 2640 | elapsed:  4.7min finished\n",
      "Best estimator RandomForestClassifier(class_weight='balanced', max_depth=6, n_jobs=-1,\n",
      "                       random_state=42)\n",
      "Best results 0.5148095238095238\n",
      "Best params {'class_weight': 'balanced', 'max_depth': 6, 'n_estimators': 100}\n",
      "accuracy (mean, std) 0.5200000000000001 0.2712931993250107\n",
      "f1 (mean, std) 0.5148095238095238 0.2987683829544706\n",
      "balanced accuracy (mean, std) 0.5417592592592594 0.2608484527363054\n",
      "precision (mean, std) 0.6175555555555555 0.35567768735745936\n",
      "recall (mean, std) 0.5200000000000001 0.2712931993250107\n",
      "\n",
      "f1_score (weighted) 0.4995366710064308\n",
      "accuracy 0.52\n"
     ]
    }
   ],
   "source": [
    "best_result, y_predict, y_predict_proba, result_list = runGridSearchClassifiers(X_audio, y_audio, cv_loo, models_list, parameters_list, \n",
    "                                                                output_predict=True, n_jobs=-1, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ypredict = pd.concat([X_audio.reset_index()[['video_name','diapo']],pd.DataFrame(y_predict, columns=['ypredict'])],axis=1)\n",
    "df_ypredict.to_csv('ypredict_' + features + '_diapo' + diapo_selection + '.csv')"
   ]
  },
  {
   "source": [
    "## Stress global\n",
    "### All diapos"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "diapo_selection = '_all'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ypredict = pd.read_csv('ypredict_' + features + '_diapo' + diapo_selection + '.csv')\n",
    "df_ypredict = df_ypredict.drop(df_ypredict.columns[0],axis=1)\n",
    "df_ypredict.columns = ['video_name','diapo','ypredict']\n",
    "ypredict_stress_diapo = df_ypredict.pivot_table(values='ypredict', columns='diapo',index='video_name',aggfunc='mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "metadata": {},
     "execution_count": 21
    }
   ],
   "source": [
    "df_ypredict.video_name.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_annotations_stress_diapo = df_total.pivot_table(values='stress', index='video_name',columns='diapo', aggfunc='mean')\n",
    "#df_annotations_stress_global = df_total.pivot_table(values='stress_global', index='video_name', aggfunc='mean')\n",
    "#df_annotations_stress = df_annotations_stress_diapo.merge(df_annotations_stress_global, on='video_name')\n",
    "#df_annotations_stress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_annotations_stress = pd.read_csv('annotations.csv')"
   ]
  },
  {
   "source": [
    "#### En utilisant les annotations comme X"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "models_list = [\n",
    "                LogisticRegression(multi_class='multinomial', fit_intercept=True, random_state=42),\n",
    "                KNeighborsClassifier(),\n",
    "                RandomForestClassifier(random_state = 42, n_jobs=-1)\n",
    "                ]\n",
    "\n",
    "parameters_list = [\n",
    "                    {'C': [0.01, 0.05, 0.1, 0.5, 1, 2], 'class_weight' : [None, 'balanced']},\n",
    "                    {'n_neighbors': [4, 5, 6, 7, 8, 9, 10, 11, 12,  15, 20], 'weights' : ['uniform', 'distance'], 'p': [1, 2]},\n",
    "                    {'n_estimators': [50, 100, 150, 200], 'max_depth':[3, 4, 5, 6, 10, 15, 20], 'class_weight':[None,'balanced']}\n",
    "                    ]\n",
    "X = df_annotations_stress.iloc[:,:-1].set_index('video_name')\n",
    "y = df_annotations_stress.iloc[:,-1]\n",
    "cv = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  45 out of  60 | elapsed:    0.3s remaining:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done  60 out of  60 | elapsed:    0.4s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "Best estimator LogisticRegression(C=0.1, multi_class='multinomial', random_state=42)\n",
      "Best results 0.7651587301587301\n",
      "Best params {'C': 0.1, 'class_weight': None}\n",
      "accuracy (mean, std) 0.8 0.0666666666666667\n",
      "f1 (mean, std) 0.7651587301587301 0.11176124986563704\n",
      "balanced accuracy (mean, std) 0.8 0.0666666666666667\n",
      "precision (mean, std) 0.8016666666666665 0.16758635142870432\n",
      "recall (mean, std) 0.8 0.0666666666666667\n",
      "\n",
      "Fitting 5 folds for each of 44 candidates, totalling 220 fits\n",
      "[Parallel(n_jobs=-1)]: Done  56 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=-1)]: Done 220 out of 220 | elapsed:    0.7s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "Best estimator KNeighborsClassifier(n_neighbors=6, weights='distance')\n",
      "Best results 0.8114285714285714\n",
      "Best params {'n_neighbors': 6, 'p': 2, 'weights': 'distance'}\n",
      "accuracy (mean, std) 0.8333333333333334 0.10540925533894599\n",
      "f1 (mean, std) 0.8114285714285714 0.1285043916946314\n",
      "balanced accuracy (mean, std) 0.8 0.16329931618554522\n",
      "precision (mean, std) 0.8388888888888889 0.15530734164993737\n",
      "recall (mean, std) 0.8333333333333334 0.10540925533894599\n",
      "\n",
      "Fitting 5 folds for each of 56 candidates, totalling 280 fits\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    2.2s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:   11.8s\n",
      "Best estimator RandomForestClassifier(class_weight='balanced', max_depth=4, n_jobs=-1,\n",
      "                       random_state=42)\n",
      "Best results 0.7501587301587301\n",
      "Best params {'class_weight': 'balanced', 'max_depth': 4, 'n_estimators': 100}\n",
      "accuracy (mean, std) 0.7666666666666666 0.13333333333333336\n",
      "f1 (mean, std) 0.7501587301587301 0.14529697826233098\n",
      "balanced accuracy (mean, std) 0.7444444444444445 0.16703662642636563\n",
      "precision (mean, std) 0.7861111111111111 0.16282612099725385\n",
      "recall (mean, std) 0.7666666666666666 0.13333333333333336\n",
      "\n",
      "f1_score (weighted) 0.8297410192147034\n",
      "accuracy 0.8333333333333334\n",
      "[Parallel(n_jobs=-1)]: Done 280 out of 280 | elapsed:   17.9s finished\n"
     ]
    }
   ],
   "source": [
    "best_result, y_predict, y_predict_proba, result_list = runGridSearchClassifiers(X, y, 5, models_list, parameters_list, \n",
    "                                                                output_predict=True, n_jobs=-1, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Accuracy 0.3333333333333333\nF1 0.2857142857142857\nBalanced accuracy 0.3055555555555556\nPrecision 0.25925925925925924\nRecall 0.3333333333333333\n"
     ]
    }
   ],
   "source": [
    "ypredict_stress_global = best_result['best_estimator'].predict(ypredict_stress_diapo)\n",
    "from sklearn.metrics import accuracy_score, f1_score, balanced_accuracy_score, precision_score, recall_score\n",
    "print('Accuracy',accuracy_score(y.values,ypredict_stress_global))\n",
    "print('F1',f1_score(y.values,ypredict_stress_global, average='weighted'))\n",
    "print('Balanced accuracy',balanced_accuracy_score(y.values,ypredict_stress_global))\n",
    "print('Precision',precision_score(y.values,ypredict_stress_global, average='weighted'))\n",
    "print('Recall',recall_score(y.values,ypredict_stress_global, average='weighted'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                         video_name  stress_global  predicted_stress_global\n",
       "0                    Test_pour_AFPA            1.0                      1.0\n",
       "1                           Video_1            0.0                      0.0\n",
       "2         WIN_20210323_19_17_40_Pro            1.0                      0.0\n",
       "3         WIN_20210329_10_16_02_Pro            1.0                      1.0\n",
       "4         WIN_20210330_13_10_29_Pro            0.0                      1.0\n",
       "5         WIN_20210331_21_22_52_Pro            1.0                      0.0\n",
       "6         WIN_20210402_14_27_50_Pro            1.0                      1.0\n",
       "7         WIN_20210402_19_04_53_Pro            2.0                      1.0\n",
       "8         WIN_20210403_18_49_15_Pro            2.0                      1.0\n",
       "9         WIN_20210404_10_58_27_Pro            1.0                      1.0\n",
       "10        WIN_20210404_21_41_12_Pro            0.0                      1.0\n",
       "11        WIN_20210405_15_09_16_Pro            1.0                      0.0\n",
       "12        WIN_20210406_15_06_15_Pro            2.0                      0.0\n",
       "13        WIN_20210406_18_35_52_Pro            0.0                      0.0\n",
       "14        WIN_20210406_18_49_10_Pro            1.0                      1.0\n",
       "15        WIN_20210406_21_05_52_Pro            2.0                      1.0\n",
       "16        WIN_20210407_09_04_05_Pro            2.0                      1.0\n",
       "17  WIN_20210407_14_54_56_Pro_edit2            0.0                      0.0\n",
       "18        WIN_20210408_11_48_58_Pro            2.0                      1.0\n",
       "19        WIN_20210408_14_00_44_Pro            0.0                      1.0\n",
       "20        WIN_20210408_14_02_19_Pro            0.0                      1.0\n",
       "21        WIN_20210408_14_11_32_Pro            2.0                      1.0\n",
       "22        WIN_20210408_15_20_51_Pro            0.0                      1.0\n",
       "23        WIN_20210408_16_04_32_Pro            0.0                      0.0\n",
       "24        WIN_20210409_10_26_11_Pro            0.0                      0.0\n",
       "25        WIN_20210413_15_38_01_Pro            1.0                      0.0\n",
       "26        WIN_20210414_06_24_52_Pro            2.0                      0.0\n",
       "27        WIN_20210415_15_41_24_Pro            0.0                      1.0\n",
       "28        WIN_20210416_08_06_54_Pro            1.0                      0.0\n",
       "29        WIN_20210417_14_53_12_Pro            0.0                      1.0"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>video_name</th>\n      <th>stress_global</th>\n      <th>predicted_stress_global</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Test_pour_AFPA</td>\n      <td>1.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Video_1</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>WIN_20210323_19_17_40_Pro</td>\n      <td>1.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>WIN_20210329_10_16_02_Pro</td>\n      <td>1.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>WIN_20210330_13_10_29_Pro</td>\n      <td>0.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>WIN_20210331_21_22_52_Pro</td>\n      <td>1.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>WIN_20210402_14_27_50_Pro</td>\n      <td>1.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>WIN_20210402_19_04_53_Pro</td>\n      <td>2.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>WIN_20210403_18_49_15_Pro</td>\n      <td>2.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>WIN_20210404_10_58_27_Pro</td>\n      <td>1.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>WIN_20210404_21_41_12_Pro</td>\n      <td>0.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>WIN_20210405_15_09_16_Pro</td>\n      <td>1.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>WIN_20210406_15_06_15_Pro</td>\n      <td>2.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>WIN_20210406_18_35_52_Pro</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>WIN_20210406_18_49_10_Pro</td>\n      <td>1.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>WIN_20210406_21_05_52_Pro</td>\n      <td>2.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>WIN_20210407_09_04_05_Pro</td>\n      <td>2.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>WIN_20210407_14_54_56_Pro_edit2</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>WIN_20210408_11_48_58_Pro</td>\n      <td>2.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>WIN_20210408_14_00_44_Pro</td>\n      <td>0.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>WIN_20210408_14_02_19_Pro</td>\n      <td>0.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>WIN_20210408_14_11_32_Pro</td>\n      <td>2.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>WIN_20210408_15_20_51_Pro</td>\n      <td>0.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>WIN_20210408_16_04_32_Pro</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>24</th>\n      <td>WIN_20210409_10_26_11_Pro</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>25</th>\n      <td>WIN_20210413_15_38_01_Pro</td>\n      <td>1.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>26</th>\n      <td>WIN_20210414_06_24_52_Pro</td>\n      <td>2.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>27</th>\n      <td>WIN_20210415_15_41_24_Pro</td>\n      <td>0.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>28</th>\n      <td>WIN_20210416_08_06_54_Pro</td>\n      <td>1.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>29</th>\n      <td>WIN_20210417_14_53_12_Pro</td>\n      <td>0.0</td>\n      <td>1.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 27
    }
   ],
   "source": [
    "pd.concat([X.reset_index().iloc[:,0],y, pd.DataFrame(ypredict_stress_global,columns=['predicted_stress_global'])],axis=1)"
   ]
  },
  {
   "source": [
    "#### En utilisant les prédictions comme annotations"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import LeaveOneGroupOut\n",
    "\n",
    "models_list = [\n",
    "                LogisticRegression(multi_class='multinomial', fit_intercept=True, random_state=42),\n",
    "                KNeighborsClassifier(),\n",
    "                RandomForestClassifier(random_state = 42, n_jobs=-1)\n",
    "                ]\n",
    "\n",
    "parameters_list = [\n",
    "                    {'C': [0.01, 0.05, 0.1, 0.5, 1, 2, 3, 4 , 5, 10], 'class_weight' : [None, 'balanced']},\n",
    "                    {'n_neighbors': [4, 5, 6, 7, 8, 9, 10, 11, 12,  15, 20], 'weights' : ['uniform', 'distance'], 'p': [1, 2]},\n",
    "                    {'n_estimators': [50, 100, 150, 200], 'max_depth':[3, 4, 5, 6, 10, 15, 20], 'class_weight':[None,'balanced']}\n",
    "                    ]\n",
    "X = ypredict_stress_diapo\n",
    "y = df_annotations_stress.iloc[:,-1]\n",
    "groups = X.reset_index()['video_name']\n",
    "loo = LeaveOneGroupOut()\n",
    "cv_loo = loo.split(X, y, groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  56 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    0.6s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "Best estimator LogisticRegression(C=0.1, multi_class='multinomial', random_state=42)\n",
      "Best results 0.3638888888888889\n",
      "Best params {'C': 0.1, 'class_weight': None}\n",
      "accuracy (mean, std) 0.4666666666666666 0.12472191289246472\n",
      "f1 (mean, std) 0.3638888888888889 0.1702727792395549\n",
      "balanced accuracy (mean, std) 0.39999999999999997 0.08164965809277262\n",
      "precision (mean, std) 0.3483333333333333 0.2183524164688309\n",
      "recall (mean, std) 0.4666666666666666 0.12472191289246472\n",
      "\n",
      "Fitting 5 folds for each of 44 candidates, totalling 220 fits\n",
      "[Parallel(n_jobs=-1)]: Done  56 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=-1)]: Done 220 out of 220 | elapsed:    0.7s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "Best estimator KNeighborsClassifier(p=1)\n",
      "Best results 0.44031746031746033\n",
      "Best params {'n_neighbors': 5, 'p': 1, 'weights': 'uniform'}\n",
      "accuracy (mean, std) 0.5 0.18257418583505539\n",
      "f1 (mean, std) 0.44031746031746033 0.1679560105097889\n",
      "balanced accuracy (mean, std) 0.4444444444444445 0.1531560972454469\n",
      "precision (mean, std) 0.42666666666666664 0.16033914673375507\n",
      "recall (mean, std) 0.5 0.18257418583505539\n",
      "\n",
      "Fitting 5 folds for each of 56 candidates, totalling 280 fits\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    2.2s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:   11.6s\n",
      "[Parallel(n_jobs=-1)]: Done 280 out of 280 | elapsed:   17.5s finished\n",
      "Best estimator RandomForestClassifier(max_depth=5, n_estimators=200, n_jobs=-1,\n",
      "                       random_state=42)\n",
      "Best results 0.3057142857142857\n",
      "Best params {'class_weight': None, 'max_depth': 5, 'n_estimators': 200}\n",
      "accuracy (mean, std) 0.36666666666666664 0.19436506316151\n",
      "f1 (mean, std) 0.3057142857142857 0.16235728853624504\n",
      "balanced accuracy (mean, std) 0.3222222222222222 0.17356110390903676\n",
      "precision (mean, std) 0.275 0.14813657362192648\n",
      "recall (mean, std) 0.36666666666666664 0.19436506316151\n",
      "\n",
      "f1_score (weighted) 0.4425287356321839\n",
      "accuracy 0.5\n"
     ]
    }
   ],
   "source": [
    "best_result, y_predict, y_predict_proba, result_list = runGridSearchClassifiers(X, y, 5, models_list, parameters_list, \n",
    "                                                                output_predict=True, n_jobs=-1, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'best_estimator': KNeighborsClassifier(p=1),\n",
       " 'best_score': 0.44031746031746033,\n",
       " 'best_params': {'n_neighbors': 5, 'p': 1, 'weights': 'uniform'},\n",
       " 'mean_test_f1_score': 0.44031746031746033,\n",
       " 'std_test_f1_score': 0.1679560105097889,\n",
       " 'mean_test_accuracy_score': 0.5,\n",
       " 'std_test_accuracy_score': 0.18257418583505539,\n",
       " 'mean_test_balanced_accuracy_score': 0.4444444444444445,\n",
       " 'std_test_balanced_accuracy_score': 0.1531560972454469,\n",
       " 'mean_test_precision': 0.42666666666666664,\n",
       " 'std_test_precision': 0.16033914673375507,\n",
       " 'mean_test_recall': 0.5,\n",
       " 'std_test_recall': 0.18257418583505539}"
      ]
     },
     "metadata": {},
     "execution_count": 30
    }
   ],
   "source": [
    "best_result"
   ]
  },
  {
   "source": [
    "### Audio diapos only"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "diapo_selection = '_audio_only'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ypredict = pd.read_csv('ypredict_' + features + '_diapo' + diapo_selection + '.csv')\n",
    "df_ypredict = df_ypredict.drop(df_ypredict.columns[0],axis=1)\n",
    "df_ypredict.columns = ['video_name','diapo','ypredict']\n",
    "ypredict_stress_diapo = df_ypredict.pivot_table(values='ypredict', columns='diapo',index='video_name',aggfunc='mean')"
   ]
  },
  {
   "source": [
    "#### En utilisant les annotations comme X"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "models_list = [\n",
    "                LogisticRegression(multi_class='multinomial', fit_intercept=True, random_state=42),\n",
    "                KNeighborsClassifier(),\n",
    "                RandomForestClassifier(random_state = 42, n_jobs=-1)\n",
    "                ]\n",
    "\n",
    "parameters_list = [\n",
    "                    {'C': [0.01, 0.05, 0.1, 0.5, 1, 2], 'class_weight' : [None, 'balanced']},\n",
    "                    {'n_neighbors': [4, 5, 6, 7, 8, 9, 10, 11, 12,  15, 20], 'weights' : ['uniform', 'distance'], 'p': [1, 2]},\n",
    "                    {'n_estimators': [50, 100, 150, 200], 'max_depth':[3, 4, 5, 6, 10, 15, 20], 'class_weight':[None,'balanced']}\n",
    "                    ]\n",
    "X = df_annotations_stress[['video_name','8','9','10','11','17','stress_global']].iloc[:,:-1].set_index('video_name')\n",
    "y = df_annotations_stress.iloc[:,-1]\n",
    "cv = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  45 out of  60 | elapsed:    0.2s remaining:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done  60 out of  60 | elapsed:    0.3s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "Best estimator LogisticRegression(C=0.1, class_weight='balanced', multi_class='multinomial',\n",
      "                   random_state=42)\n",
      "Best results 0.7092063492063492\n",
      "Best params {'C': 0.1, 'class_weight': 'balanced'}\n",
      "accuracy (mean, std) 0.7666666666666667 0.08164965809277264\n",
      "f1 (mean, std) 0.7092063492063492 0.134722169623853\n",
      "balanced accuracy (mean, std) 0.7666666666666667 0.08164965809277264\n",
      "precision (mean, std) 0.7166666666666666 0.20042393341719386\n",
      "recall (mean, std) 0.7666666666666667 0.08164965809277264\n",
      "\n",
      "Fitting 5 folds for each of 44 candidates, totalling 220 fits\n",
      "[Parallel(n_jobs=-1)]: Done  56 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=-1)]: Done 220 out of 220 | elapsed:    0.6s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "Best estimator KNeighborsClassifier(n_neighbors=8, weights='distance')\n",
      "Best results 0.7358730158730158\n",
      "Best params {'n_neighbors': 8, 'p': 2, 'weights': 'distance'}\n",
      "accuracy (mean, std) 0.7666666666666667 0.16996731711975951\n",
      "f1 (mean, std) 0.7358730158730158 0.19420840873059006\n",
      "balanced accuracy (mean, std) 0.7333333333333334 0.2\n",
      "precision (mean, std) 0.7611111111111111 0.20134578082689025\n",
      "recall (mean, std) 0.7666666666666667 0.16996731711975951\n",
      "\n",
      "Fitting 5 folds for each of 56 candidates, totalling 280 fits\n",
      "[Parallel(n_jobs=-1)]: Done  52 tasks      | elapsed:    3.4s\n",
      "[Parallel(n_jobs=-1)]: Done 240 tasks      | elapsed:   14.5s\n",
      "[Parallel(n_jobs=-1)]: Done 280 out of 280 | elapsed:   16.9s finished\n",
      "Best estimator RandomForestClassifier(max_depth=4, n_estimators=150, n_jobs=-1,\n",
      "                       random_state=42)\n",
      "Best results 0.6834920634920635\n",
      "Best params {'class_weight': None, 'max_depth': 4, 'n_estimators': 150}\n",
      "accuracy (mean, std) 0.7 0.12472191289246475\n",
      "f1 (mean, std) 0.6834920634920635 0.13777046282973532\n",
      "balanced accuracy (mean, std) 0.711111111111111 0.12372809695177828\n",
      "precision (mean, std) 0.7527777777777778 0.14917468424552835\n",
      "recall (mean, std) 0.7 0.12472191289246475\n",
      "\n",
      "f1_score (weighted) 0.7541478129713425\n",
      "accuracy 0.7666666666666667\n"
     ]
    }
   ],
   "source": [
    "best_result, y_predict, y_predict_proba, result_list = runGridSearchClassifiers(X, y, cv, models_list, parameters_list, \n",
    "                                                                output_predict=True, n_jobs=-1, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Accuracy 0.4\nF1 0.3833943833943835\nBalanced accuracy 0.36944444444444446\nPrecision 0.37454545454545457\nRecall 0.4\n"
     ]
    }
   ],
   "source": [
    "ypredict_stress_global = best_result['best_estimator'].predict(ypredict_stress_diapo)\n",
    "from sklearn.metrics import accuracy_score, f1_score, balanced_accuracy_score, precision_score, recall_score\n",
    "print('Accuracy',accuracy_score(y.values,ypredict_stress_global))\n",
    "print('F1',f1_score(y.values,ypredict_stress_global, average='weighted'))\n",
    "print('Balanced accuracy',balanced_accuracy_score(y.values,ypredict_stress_global))\n",
    "print('Precision',precision_score(y.values,ypredict_stress_global, average='weighted'))\n",
    "print('Recall',recall_score(y.values,ypredict_stress_global, average='weighted'))"
   ]
  },
  {
   "source": [
    "#### En utilisant les prédictions des diapos"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import LeaveOneGroupOut\n",
    "\n",
    "models_list = [\n",
    "                LogisticRegression(multi_class='multinomial', fit_intercept=True, random_state=42),\n",
    "                KNeighborsClassifier(),\n",
    "                RandomForestClassifier(random_state = 42, n_jobs=-1)\n",
    "                ]\n",
    "\n",
    "parameters_list = [\n",
    "                    {'C': [0.01, 0.05, 0.1, 0.5, 1, 2], 'class_weight' : [None, 'balanced']},\n",
    "                    {'n_neighbors': [4, 5, 6, 7, 8, 9, 10, 11, 12,  15, 20], 'weights' : ['uniform', 'distance'], 'p': [1, 2]},\n",
    "                    {'n_estimators': [50, 100, 150, 200], 'max_depth':[3, 4, 5, 6, 10, 15, 20], 'class_weight':[None,'balanced']}\n",
    "                    ]\n",
    "X = ypredict_stress_diapo\n",
    "y = df_annotations_stress.iloc[:,-1]\n",
    "groups = X.reset_index()['video_name']\n",
    "loo = LeaveOneGroupOut()\n",
    "cv_loo = loo.split(X, y, groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  60 out of  60 | elapsed:    0.3s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "Best estimator LogisticRegression(C=1, multi_class='multinomial', random_state=42)\n",
      "Best results 0.4147619047619047\n",
      "Best params {'C': 1, 'class_weight': None}\n",
      "accuracy (mean, std) 0.4666666666666666 0.12472191289246472\n",
      "f1 (mean, std) 0.4147619047619047 0.1751201581511372\n",
      "balanced accuracy (mean, std) 0.4444444444444445 0.1531560972454469\n",
      "precision (mean, std) 0.4222222222222222 0.21648140227480092\n",
      "recall (mean, std) 0.4666666666666666 0.12472191289246472\n",
      "\n",
      "Fitting 5 folds for each of 44 candidates, totalling 220 fits\n",
      "[Parallel(n_jobs=-1)]: Done  56 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=-1)]: Done 220 out of 220 | elapsed:    0.6s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "Best estimator KNeighborsClassifier(p=1, weights='distance')\n",
      "Best results 0.40777777777777774\n",
      "Best params {'n_neighbors': 5, 'p': 1, 'weights': 'distance'}\n",
      "accuracy (mean, std) 0.4333333333333333 0.08164965809277261\n",
      "f1 (mean, std) 0.40777777777777774 0.09542626912703947\n",
      "balanced accuracy (mean, std) 0.3888888888888889 0.10540925533894598\n",
      "precision (mean, std) 0.44000000000000006 0.134550004473072\n",
      "recall (mean, std) 0.4333333333333333 0.08164965809277261\n",
      "\n",
      "Fitting 5 folds for each of 56 candidates, totalling 280 fits\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    2.4s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:   11.2s\n",
      "[Parallel(n_jobs=-1)]: Done 280 out of 280 | elapsed:   17.2s finished\n",
      "Best estimator RandomForestClassifier(max_depth=4, n_estimators=150, n_jobs=-1,\n",
      "                       random_state=42)\n",
      "Best results 0.37777777777777777\n",
      "Best params {'class_weight': None, 'max_depth': 4, 'n_estimators': 150}\n",
      "accuracy (mean, std) 0.39999999999999997 0.13333333333333336\n",
      "f1 (mean, std) 0.37777777777777777 0.12151309435104281\n",
      "balanced accuracy (mean, std) 0.37777777777777777 0.146565621758588\n",
      "precision (mean, std) 0.4222222222222222 0.14635488747021652\n",
      "recall (mean, std) 0.39999999999999997 0.13333333333333336\n",
      "\n",
      "f1_score (weighted) 0.4639999999999999\n",
      "accuracy 0.4666666666666667\n"
     ]
    }
   ],
   "source": [
    "best_result, y_predict, y_predict_proba, result_list = runGridSearchClassifiers(X, y, 5, models_list, parameters_list, \n",
    "                                                                output_predict=True, n_jobs=-1, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'best_estimator': LogisticRegression(C=1, multi_class='multinomial', random_state=42),\n",
       " 'best_score': 0.4147619047619047,\n",
       " 'best_params': {'C': 1, 'class_weight': None},\n",
       " 'mean_test_f1_score': 0.4147619047619047,\n",
       " 'std_test_f1_score': 0.1751201581511372,\n",
       " 'mean_test_accuracy_score': 0.4666666666666666,\n",
       " 'std_test_accuracy_score': 0.12472191289246472,\n",
       " 'mean_test_balanced_accuracy_score': 0.4444444444444445,\n",
       " 'std_test_balanced_accuracy_score': 0.1531560972454469,\n",
       " 'mean_test_precision': 0.4222222222222222,\n",
       " 'std_test_precision': 0.21648140227480092,\n",
       " 'mean_test_recall': 0.4666666666666666,\n",
       " 'std_test_recall': 0.12472191289246472}"
      ]
     },
     "metadata": {},
     "execution_count": 38
    }
   ],
   "source": [
    "best_result"
   ]
  },
  {
   "source": [
    "## Aggregation all frames within the video to predict the global stress"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "#### All diapo"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import kurtosis, skew\n",
    "\n",
    "def percentil25(x): \n",
    "    return np.percentile(x, q=25)\n",
    "\n",
    "def percentil75(x): \n",
    "    return np.percentile(x, q=75)\n",
    "\n",
    "X = df_total.iloc[:,2:].groupby(['video_name']).agg({'mean','min','max', 'median', 'std', percentil25, percentil75, kurtosis, skew}).iloc[:,:-27]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df_total.iloc[:,2:].groupby(['video_name']).agg({'stress_global':'mean'}).iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import LeaveOneGroupOut\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "pca = PCA()\n",
    "pipe = Pipeline(steps=[('pca', pca), ('logistic', LogisticRegression(multi_class='multinomial', fit_intercept=True, random_state=42))])\n",
    "\n",
    "models_list = [\n",
    "                LogisticRegression(multi_class='multinomial', fit_intercept=True, random_state=42),\n",
    "                pipe,\n",
    "                KNeighborsClassifier(),\n",
    "                Pipeline(steps=[('pca', pca), ('knn', KNeighborsClassifier())]),\n",
    "                RandomForestClassifier(random_state = 42, n_jobs=-1)\n",
    "                ]\n",
    "\n",
    "parameters_list = [\n",
    "                    {'C': [0.01, 0.05, 0.1, 0.5, 1, 2, 3, 4 , 5, 10], 'class_weight' : [None, 'balanced']},\n",
    "                    {'pca__n_components': [1, 2, 3, 4],\n",
    "                        'logistic__C': [0.01, 0.05, 0.1, 0.5, 1, 2, 3, 4 , 5, 10], 'logistic__class_weight' : [None, 'balanced']},\n",
    "                    {'n_neighbors': [4, 5, 6, 7, 8, 9, 10, 11, 12,  15, 20], 'weights' : ['uniform', 'distance'], 'p': [1, 2]},\n",
    "                    {'pca__n_components': [1, 2, 3, 4],\n",
    "                        'knn__n_neighbors': [4, 5, 6, 7, 8, 9, 10, 11, 12,  15, 20], 'knn__weights' : ['uniform', 'distance'],                              'knn__p': [1, 2]},\n",
    "                    {'n_estimators': [50, 100, 150, 200], 'max_depth':[3, 4, 5, 6, 10, 15, 20], 'class_weight':[None,'balanced']}\n",
    "                    ]\n",
    "\n",
    "groups = X.reset_index()['video_name']\n",
    "loo = LeaveOneGroupOut()\n",
    "cv_loo = loo.split(X, y, groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    1.5s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    3.8s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "Best estimator LogisticRegression(C=0.5, multi_class='multinomial', random_state=42)\n",
      "Best results 0.11714285714285715\n",
      "Best params {'C': 0.5, 'class_weight': None}\n",
      "accuracy (mean, std) 0.13333333333333333 0.1247219128924647\n",
      "f1 (mean, std) 0.11714285714285715 0.10823674396324094\n",
      "balanced accuracy (mean, std) 0.11111111111111109 0.09296222517045283\n",
      "precision (mean, std) 0.10555555555555554 0.09686442096757052\n",
      "recall (mean, std) 0.13333333333333333 0.1247219128924647\n",
      "\n",
      "Fitting 5 folds for each of 80 candidates, totalling 400 fits\n",
      "[Parallel(n_jobs=-1)]: Done  52 tasks      | elapsed:    0.6s\n",
      "[Parallel(n_jobs=-1)]: Done 352 tasks      | elapsed:    3.0s\n",
      "[Parallel(n_jobs=-1)]: Done 400 out of 400 | elapsed:    3.4s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "Best estimator Pipeline(steps=[('pca', PCA(n_components=1)),\n",
      "                ('logistic',\n",
      "                 LogisticRegression(C=0.01, multi_class='multinomial',\n",
      "                                    random_state=42))])\n",
      "Best results 0.34\n",
      "Best params {'logistic__C': 0.01, 'logistic__class_weight': None, 'pca__n_components': 1}\n",
      "accuracy (mean, std) 0.4 0.2\n",
      "f1 (mean, std) 0.34 0.17236195048591393\n",
      "balanced accuracy (mean, std) 0.39999999999999997 0.22054925823643562\n",
      "precision (mean, std) 0.32499999999999996 0.17950549357115014\n",
      "recall (mean, std) 0.4 0.2\n",
      "\n",
      "Fitting 5 folds for each of 44 candidates, totalling 220 fits\n",
      "[Parallel(n_jobs=-1)]: Done  56 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=-1)]: Done 220 out of 220 | elapsed:    1.2s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "Best estimator KNeighborsClassifier(n_neighbors=7, p=1)\n",
      "Best results 0.3734126984126984\n",
      "Best params {'n_neighbors': 7, 'p': 1, 'weights': 'uniform'}\n",
      "accuracy (mean, std) 0.4666666666666666 0.19436506316151\n",
      "f1 (mean, std) 0.3734126984126984 0.2047572904611129\n",
      "balanced accuracy (mean, std) 0.4111111111111111 0.16703662642636563\n",
      "precision (mean, std) 0.34555555555555556 0.22111948616187996\n",
      "recall (mean, std) 0.4666666666666666 0.19436506316151\n",
      "\n",
      "Fitting 5 folds for each of 176 candidates, totalling 880 fits\n",
      "[Parallel(n_jobs=-1)]: Done  56 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=-1)]: Done 656 tasks      | elapsed:    3.6s\n",
      "[Parallel(n_jobs=-1)]: Done 880 out of 880 | elapsed:    4.8s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "Best estimator Pipeline(steps=[('pca', PCA(n_components=1)),\n",
      "                ('knn', KNeighborsClassifier(n_neighbors=10, p=1))])\n",
      "Best results 0.42666666666666675\n",
      "Best params {'knn__n_neighbors': 10, 'knn__p': 1, 'knn__weights': 'uniform', 'pca__n_components': 1}\n",
      "accuracy (mean, std) 0.5 0.18257418583505536\n",
      "f1 (mean, std) 0.42666666666666675 0.18400214706208398\n",
      "balanced accuracy (mean, std) 0.45555555555555555 0.14656562175858795\n",
      "precision (mean, std) 0.3944444444444444 0.20214894887400278\n",
      "recall (mean, std) 0.5 0.18257418583505536\n",
      "\n",
      "Fitting 5 folds for each of 56 candidates, totalling 280 fits\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    2.3s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:   11.6s\n",
      "[Parallel(n_jobs=-1)]: Done 280 out of 280 | elapsed:   17.7s finished\n",
      "Best estimator RandomForestClassifier(max_depth=4, n_estimators=200, n_jobs=-1,\n",
      "                       random_state=42)\n",
      "Best results 0.24833333333333335\n",
      "Best params {'class_weight': None, 'max_depth': 4, 'n_estimators': 200}\n",
      "accuracy (mean, std) 0.3 0.16329931618554522\n",
      "f1 (mean, std) 0.24833333333333335 0.11647603473104098\n",
      "balanced accuracy (mean, std) 0.25555555555555554 0.14315665251916806\n",
      "precision (mean, std) 0.22111111111111112 0.09365025558091322\n",
      "recall (mean, std) 0.3 0.16329931618554522\n",
      "\n",
      "f1_score (weighted) 0.42370370370370375\n",
      "accuracy 0.5\n"
     ]
    }
   ],
   "source": [
    "best_result, y_predict,y_predict_proba, result_list = runGridSearchClassifiers(X, y, 5, models_list, parameters_list, \n",
    "                                                                output_predict=True, n_jobs=-1, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'best_estimator': Pipeline(steps=[('pca', PCA(n_components=1)),\n",
       "                 ('knn', KNeighborsClassifier(n_neighbors=10, p=1))]),\n",
       " 'best_score': 0.42666666666666675,\n",
       " 'best_params': {'knn__n_neighbors': 10,\n",
       "  'knn__p': 1,\n",
       "  'knn__weights': 'uniform',\n",
       "  'pca__n_components': 1},\n",
       " 'mean_test_f1_score': 0.42666666666666675,\n",
       " 'std_test_f1_score': 0.18400214706208398,\n",
       " 'mean_test_accuracy_score': 0.5,\n",
       " 'std_test_accuracy_score': 0.18257418583505536,\n",
       " 'mean_test_balanced_accuracy_score': 0.45555555555555555,\n",
       " 'std_test_balanced_accuracy_score': 0.14656562175858795,\n",
       " 'mean_test_precision': 0.3944444444444444,\n",
       " 'std_test_precision': 0.20214894887400278,\n",
       " 'mean_test_recall': 0.5,\n",
       " 'std_test_recall': 0.18257418583505536}"
      ]
     },
     "metadata": {},
     "execution_count": 43
    }
   ],
   "source": [
    "best_result"
   ]
  },
  {
   "source": [
    "#### Audio diapo only"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import kurtosis, skew\n",
    "\n",
    "def percentil25(x): \n",
    "    return np.percentile(x, q=25)\n",
    "\n",
    "def percentil75(x): \n",
    "    return np.percentile(x, q=75)\n",
    "\n",
    "X_audio = df_total[df_total.diapo.isin([8,9,10,11,17])].iloc[:,2:].groupby(['video_name']).agg({'mean','min','max', 'median', 'std', percentil25, percentil75, kurtosis, skew}).iloc[:,:-27]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df_total.iloc[:,2:].groupby(['video_name']).agg({'stress_global':'mean'}).iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import LeaveOneGroupOut\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "pca = PCA()\n",
    "pipe = Pipeline(steps=[('pca', pca), ('logistic', LogisticRegression(multi_class='multinomial', fit_intercept=True, random_state=42))])\n",
    "\n",
    "models_list = [\n",
    "                LogisticRegression(multi_class='multinomial', fit_intercept=True, random_state=42),\n",
    "                pipe,\n",
    "                KNeighborsClassifier(),\n",
    "                Pipeline(steps=[('pca', pca), ('knn', KNeighborsClassifier())]),\n",
    "                RandomForestClassifier(random_state = 42, n_jobs=-1)\n",
    "                ]\n",
    "\n",
    "parameters_list = [\n",
    "                    {'C': [0.01, 0.05, 0.1, 0.5, 1, 2, 3, 4 , 5, 10], 'class_weight' : [None, 'balanced']},\n",
    "                    {'pca__n_components': [1, 2, 3, 4],\n",
    "                        'logistic__C': [0.01, 0.05, 0.1, 0.5, 1, 2, 3, 4 , 5, 10], 'logistic__class_weight' : [None, 'balanced']},\n",
    "                    {'n_neighbors': [4, 5, 6, 7, 8, 9, 10, 11, 12,  15, 20], 'weights' : ['uniform', 'distance'], 'p': [1, 2]},\n",
    "                    {'pca__n_components': [1, 2, 3, 4],\n",
    "                        'knn__n_neighbors': [4, 5, 6, 7, 8, 9, 10, 11, 12,  15, 20], 'knn__weights' : ['uniform', 'distance'],                              'knn__p': [1, 2]},\n",
    "                    {'n_estimators': [50, 100, 150, 200], 'max_depth':[3, 4, 5, 6, 10, 15, 20], 'class_weight':[None,'balanced']}\n",
    "                    ]\n",
    "X = X_audio\n",
    "groups = X.reset_index()['video_name']\n",
    "loo = LeaveOneGroupOut()\n",
    "cv_loo = loo.split(X, y, groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    1.4s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    3.5s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "Best estimator LogisticRegression(C=0.05, class_weight='balanced', multi_class='multinomial',\n",
      "                   random_state=42)\n",
      "Best results 0.3511111111111111\n",
      "Best params {'C': 0.05, 'class_weight': 'balanced'}\n",
      "accuracy (mean, std) 0.36666666666666664 0.19436506316151\n",
      "f1 (mean, std) 0.3511111111111111 0.20495106311411254\n",
      "balanced accuracy (mean, std) 0.3111111111111111 0.18790593916986403\n",
      "precision (mean, std) 0.3555555555555555 0.23465235646603194\n",
      "recall (mean, std) 0.36666666666666664 0.19436506316151\n",
      "\n",
      "Fitting 5 folds for each of 80 candidates, totalling 400 fits\n",
      "[Parallel(n_jobs=-1)]: Done  56 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=-1)]: Done 400 out of 400 | elapsed:    3.3s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "Best estimator Pipeline(steps=[('pca', PCA(n_components=4)),\n",
      "                ('logistic',\n",
      "                 LogisticRegression(C=0.01, multi_class='multinomial',\n",
      "                                    random_state=42))])\n",
      "Best results 0.31111111111111106\n",
      "Best params {'logistic__C': 0.01, 'logistic__class_weight': None, 'pca__n_components': 4}\n",
      "accuracy (mean, std) 0.33333333333333337 0.14907119849998599\n",
      "f1 (mean, std) 0.31111111111111106 0.17054741203866572\n",
      "balanced accuracy (mean, std) 0.28888888888888886 0.10183501544346309\n",
      "precision (mean, std) 0.31111111111111117 0.2036700308869262\n",
      "recall (mean, std) 0.33333333333333337 0.14907119849998599\n",
      "\n",
      "Fitting 5 folds for each of 44 candidates, totalling 220 fits\n",
      "[Parallel(n_jobs=-1)]: Done  56 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=-1)]: Done 205 out of 220 | elapsed:    1.1s remaining:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done 220 out of 220 | elapsed:    1.1s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "Best estimator KNeighborsClassifier(n_neighbors=4, p=1, weights='distance')\n",
      "Best results 0.3483333333333334\n",
      "Best params {'n_neighbors': 4, 'p': 1, 'weights': 'distance'}\n",
      "accuracy (mean, std) 0.39999999999999997 0.13333333333333333\n",
      "f1 (mean, std) 0.3483333333333334 0.15071434840390885\n",
      "balanced accuracy (mean, std) 0.34444444444444444 0.08888888888888888\n",
      "precision (mean, std) 0.3711111111111111 0.20007406036173112\n",
      "recall (mean, std) 0.39999999999999997 0.13333333333333333\n",
      "\n",
      "Fitting 5 folds for each of 176 candidates, totalling 880 fits\n",
      "[Parallel(n_jobs=-1)]: Done  56 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=-1)]: Done 656 tasks      | elapsed:    3.7s\n",
      "[Parallel(n_jobs=-1)]: Done 880 out of 880 | elapsed:    4.9s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "Best estimator Pipeline(steps=[('pca', PCA(n_components=1)),\n",
      "                ('knn', KNeighborsClassifier(n_neighbors=11, p=1))])\n",
      "Best results 0.3461111111111111\n",
      "Best params {'knn__n_neighbors': 11, 'knn__p': 1, 'knn__weights': 'uniform', 'pca__n_components': 1}\n",
      "accuracy (mean, std) 0.4 0.1699673171197595\n",
      "f1 (mean, std) 0.3461111111111111 0.15067338562534016\n",
      "balanced accuracy (mean, std) 0.3555555555555555 0.12957670877434002\n",
      "precision (mean, std) 0.33777777777777773 0.16874262672506335\n",
      "recall (mean, std) 0.4 0.1699673171197595\n",
      "\n",
      "Fitting 5 folds for each of 56 candidates, totalling 280 fits\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    2.2s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:   11.6s\n",
      "[Parallel(n_jobs=-1)]: Done 280 out of 280 | elapsed:   17.7s finished\n",
      "Best estimator RandomForestClassifier(class_weight='balanced', max_depth=3, n_estimators=50,\n",
      "                       n_jobs=-1, random_state=42)\n",
      "Best results 0.3326984126984127\n",
      "Best params {'class_weight': 'balanced', 'max_depth': 3, 'n_estimators': 50}\n",
      "accuracy (mean, std) 0.36666666666666664 0.19436506316151\n",
      "f1 (mean, std) 0.3326984126984127 0.1844813229803945\n",
      "balanced accuracy (mean, std) 0.32222222222222224 0.19051586888313607\n",
      "precision (mean, std) 0.3388888888888889 0.2111111111111111\n",
      "recall (mean, std) 0.36666666666666664 0.19436506316151\n",
      "\n",
      "f1_score (weighted) 0.3100762527233115\n",
      "accuracy 0.3333333333333333\n"
     ]
    }
   ],
   "source": [
    "best_result, y_predict, y_predict_proba, result_list = runGridSearchClassifiers(X, y, 5, models_list, parameters_list, \n",
    "                                                                output_predict=True, n_jobs=-1, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'best_estimator': LogisticRegression(C=0.05, class_weight='balanced', multi_class='multinomial',\n",
       "                    random_state=42),\n",
       " 'best_score': 0.3511111111111111,\n",
       " 'best_params': {'C': 0.05, 'class_weight': 'balanced'},\n",
       " 'mean_test_f1_score': 0.3511111111111111,\n",
       " 'std_test_f1_score': 0.20495106311411254,\n",
       " 'mean_test_accuracy_score': 0.36666666666666664,\n",
       " 'std_test_accuracy_score': 0.19436506316151,\n",
       " 'mean_test_balanced_accuracy_score': 0.3111111111111111,\n",
       " 'std_test_balanced_accuracy_score': 0.18790593916986403,\n",
       " 'mean_test_precision': 0.3555555555555555,\n",
       " 'std_test_precision': 0.23465235646603194,\n",
       " 'mean_test_recall': 0.36666666666666664,\n",
       " 'std_test_recall': 0.19436506316151}"
      ]
     },
     "metadata": {},
     "execution_count": 48
    }
   ],
   "source": [
    "best_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}