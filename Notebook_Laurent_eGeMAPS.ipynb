{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit ('base': conda)"
  },
  "metadata": {
   "interpreter": {
    "hash": "148f6ed9de8dadedbbd96ef8a7e818f87aaafab3c59f5306aa9910b4f09c5b3f"
   }
  },
  "interpreter": {
   "hash": "148f6ed9de8dadedbbd96ef8a7e818f87aaafab3c59f5306aa9910b4f09c5b3f"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt \n",
    "import pathlib\n",
    "from util import runGridSearchClassifiers"
   ]
  },
  {
   "source": [
    "## Loading data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory_path = '../../04_-_Dev/videos'\n",
    "features = 'eGeMAPS'#''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Number of videos 30\n",
      "Number of annotations 240\n"
     ]
    }
   ],
   "source": [
    "currentDirectory = pathlib.Path(directory_path)\n",
    "currentPattern = \"*.\" + features + \".annotated.csv\"\n",
    "file_list = [str(currentFile) for currentFile in currentDirectory.glob(currentPattern)]\n",
    "\n",
    "df_total = pd.DataFrame()\n",
    "for filename in file_list:\n",
    "    df = pd.read_csv(filename, delimiter=';')\n",
    "    df_total = pd.concat([df_total, df], axis=0)\n",
    "\n",
    "print('Number of videos', df_total['video_name'].nunique())\n",
    "print('Number of annotations', df_total[['video_name','diapo']].drop_duplicates().shape[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_total = df_total.dropna(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_total.to_pickle(directory_path + '/audio_' + features + '_data.p')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_total = pd.read_pickle(directory_path + '/audio_' + features + '_data.p')"
   ]
  },
  {
   "source": [
    "## Data pre-processing 1 - Sans utilisation de la temporalité"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import kurtosis, skew\n",
    "\n",
    "def percentil25(x): \n",
    "    return np.percentile(x, q=25)\n",
    "\n",
    "def percentil75(x): \n",
    "    return np.percentile(x, q=75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sequence as a whole with 9 agregators\n",
    "X = df_total.iloc[:,2:].groupby(['video_name','diapo']).agg({'mean','min','max', 'median', 'std', percentil25, percentil75, kurtosis, skew}).iloc[:,:-18]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sequence as a whole with 4 agregators\n",
    "#X = df_total.iloc[:,2:].groupby(['video_name','diapo']).agg({'mean','std', kurtosis, skew}).iloc[:,:-8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(240, 468)"
      ]
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_temp = df_total[['video_name','diapo','type_candidat','sexe']].groupby(['video_name','diapo']).agg({'type_candidat':'first','sexe':'first'})\n",
    "X_temp.loc[X_temp['type_candidat'] == 'Stagiaire','Stagiaire'] = 1\n",
    "X_temp.loc[X_temp['type_candidat'] != 'Stagiaire','Stagiaire'] = 0\n",
    "X_temp.loc[X_temp['sexe'] == 'F','Femme'] = 1\n",
    "X_temp.loc[X_temp['sexe'] != 'F','Femme'] = 0\n",
    "X_temp = X_temp.drop(['type_candidat','sexe'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.concat([X,X_temp],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df_total.iloc[:,2:].groupby(['video_name','diapo']).agg({'stress':'mean'}).iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "((240, 470), (240,))"
      ]
     },
     "metadata": {},
     "execution_count": 21
    }
   ],
   "source": [
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.to_pickle(directory_path + '/audio_' + features + '_data_X.p')\n",
    "y.to_pickle(directory_path + '/audio_' + features + '_data_y.p')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import kurtosis, skew\n",
    "X_audio = df_total.loc[df_total['diapo'].isin([8, 9, 10, 11, 17]),:].iloc[:,2:].groupby(['video_name','diapo']).agg({'mean','min','max', 'median', 'std', percentil25, percentil75, kurtosis, skew}).iloc[:,:-18]\n",
    "y_audio = df_total.loc[df_total['diapo'].isin([8, 9, 10, 11, 17]),:].iloc[:,2:].groupby(['video_name','diapo']).agg({'stress':'mean'}).iloc[:,-1]\n",
    "\n",
    "X_audio.to_pickle(directory_path + '/audio_' + features + '_data_X_audio.p')\n",
    "y_audio.to_pickle(directory_path + '/audio_' + features + '_data_y_audio.p')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(150, 630)"
      ]
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "X_audio.shape"
   ]
  },
  {
   "source": [
    "## Modèles"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.read_pickle(directory_path + '/audio_' + features + '_data_X.p')\n",
    "y = pd.read_pickle(directory_path + '/audio_' + features + '_data_y.p')\n",
    "\n",
    "X_audio = pd.read_pickle(directory_path + '/audio_' + features + '_data_X_audio.p')\n",
    "y_audio = pd.read_pickle(directory_path + '/audio_' + features + '_data_y_audio.p')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "((240, 623), (150, 630))"
      ]
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": [
    "X.shape, X_audio.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                 (Loudness_sma3, kurtosis)  \\\n",
       "video_name                diapo                              \n",
       "Test_pour_AFPA            1                     195.631236   \n",
       "                          8                       1.922854   \n",
       "                          9                       2.268561   \n",
       "                          10                     10.863511   \n",
       "                          11                      9.862057   \n",
       "...                                                    ...   \n",
       "WIN_20210417_14_53_12_Pro 10                      2.940143   \n",
       "                          11                      1.568983   \n",
       "                          12                      4.232695   \n",
       "                          17                      0.669043   \n",
       "                          18                     -0.914318   \n",
       "\n",
       "                                 (Loudness_sma3, max)  \\\n",
       "video_name                diapo                         \n",
       "Test_pour_AFPA            1                  3.545050   \n",
       "                          8                  2.867280   \n",
       "                          9                  3.393920   \n",
       "                          10                 5.028640   \n",
       "                          11                 5.151010   \n",
       "...                                               ...   \n",
       "WIN_20210417_14_53_12_Pro 10                 3.264950   \n",
       "                          11                 2.660928   \n",
       "                          12                 0.384004   \n",
       "                          17                 3.344785   \n",
       "                          18                 0.203776   \n",
       "\n",
       "                                 (Loudness_sma3, percentil25)  \\\n",
       "video_name                diapo                                 \n",
       "Test_pour_AFPA            1                          0.114812   \n",
       "                          8                          0.117015   \n",
       "                          9                          0.112834   \n",
       "                          10                         0.111221   \n",
       "                          11                         0.113637   \n",
       "...                                                       ...   \n",
       "WIN_20210417_14_53_12_Pro 10                         0.001104   \n",
       "                          11                         0.001126   \n",
       "                          12                         0.014089   \n",
       "                          17                         0.006968   \n",
       "                          18                         0.001236   \n",
       "\n",
       "                                 (Loudness_sma3, median)  \\\n",
       "video_name                diapo                            \n",
       "Test_pour_AFPA            1                     0.119039   \n",
       "                          8                     0.282706   \n",
       "                          9                     0.209026   \n",
       "                          10                    0.148684   \n",
       "                          11                    0.252318   \n",
       "...                                                  ...   \n",
       "WIN_20210417_14_53_12_Pro 10                    0.013893   \n",
       "                          11                    0.081050   \n",
       "                          12                    0.029460   \n",
       "                          17                    0.488653   \n",
       "                          18                    0.034392   \n",
       "\n",
       "                                 (Loudness_sma3, std)  (Loudness_sma3, mean)  \\\n",
       "video_name                diapo                                                \n",
       "Test_pour_AFPA            1                  0.130805               0.136717   \n",
       "                          8                  0.424739               0.460516   \n",
       "                          9                  0.383514               0.411576   \n",
       "                          10                 0.391520               0.382675   \n",
       "                          11                 0.381967               0.408419   \n",
       "...                                               ...                    ...   \n",
       "WIN_20210417_14_53_12_Pro 10                 0.464786               0.301682   \n",
       "                          11                 0.431815               0.330021   \n",
       "                          12                 0.038861               0.041404   \n",
       "                          17                 0.708703               0.651603   \n",
       "                          18                 0.037630               0.041692   \n",
       "\n",
       "                                 (Loudness_sma3, percentil75)  \\\n",
       "video_name                diapo                                 \n",
       "Test_pour_AFPA            1                          0.124505   \n",
       "                          8                          0.711492   \n",
       "                          9                          0.639661   \n",
       "                          10                         0.590052   \n",
       "                          11                         0.605844   \n",
       "...                                                       ...   \n",
       "WIN_20210417_14_53_12_Pro 10                         0.547356   \n",
       "                          11                         0.586716   \n",
       "                          12                         0.058949   \n",
       "                          17                         1.049473   \n",
       "                          18                         0.075999   \n",
       "\n",
       "                                 (Loudness_sma3, skew)  (Loudness_sma3, min)  \\\n",
       "video_name                diapo                                                \n",
       "Test_pour_AFPA            1                  12.240252              0.083114   \n",
       "                          8                   1.370343              0.100229   \n",
       "                          9                   1.420768              0.099458   \n",
       "                          10                  2.289813              0.099492   \n",
       "                          11                  2.060058              0.098327   \n",
       "...                                                ...                   ...   \n",
       "WIN_20210417_14_53_12_Pro 10                  1.707042              0.001034   \n",
       "                          11                  1.397632              0.001034   \n",
       "                          12                  1.654525              0.001034   \n",
       "                          17                  1.121390              0.001034   \n",
       "                          18                  0.487773              0.001034   \n",
       "\n",
       "                                 (alphaRatio_sma3, kurtosis)  ...  \\\n",
       "video_name                diapo                               ...   \n",
       "Test_pour_AFPA            1                        35.764880  ...   \n",
       "                          8                         0.110346  ...   \n",
       "                          9                         0.410082  ...   \n",
       "                          10                        0.166996  ...   \n",
       "                          11                       -0.160992  ...   \n",
       "...                                                      ...  ...   \n",
       "WIN_20210417_14_53_12_Pro 10                        0.025470  ...   \n",
       "                          11                       -0.130052  ...   \n",
       "                          12                        0.938287  ...   \n",
       "                          17                        0.245458  ...   \n",
       "                          18                        0.822559  ...   \n",
       "\n",
       "                                 (F3amplitudeLogRelF0_sma3nz_de_de, max)  \\\n",
       "video_name                diapo                                            \n",
       "Test_pour_AFPA            1                                     131.8622   \n",
       "                          8                                     143.5802   \n",
       "                          9                                     151.9159   \n",
       "                          10                                    141.5019   \n",
       "                          11                                    154.1847   \n",
       "...                                                                  ...   \n",
       "WIN_20210417_14_53_12_Pro 10                                    201.0000   \n",
       "                          11                                    143.9756   \n",
       "                          12                                    116.6289   \n",
       "                          17                                    135.7129   \n",
       "                          18                                     68.0983   \n",
       "\n",
       "                                 (F3amplitudeLogRelF0_sma3nz_de_de, percentil25)  \\\n",
       "video_name                diapo                                                    \n",
       "Test_pour_AFPA            1                                             0.000000   \n",
       "                          8                                            -0.575755   \n",
       "                          9                                            -0.272000   \n",
       "                          10                                           -0.215863   \n",
       "                          11                                           -0.406947   \n",
       "...                                                                          ...   \n",
       "WIN_20210417_14_53_12_Pro 10                                            0.000000   \n",
       "                          11                                            0.000000   \n",
       "                          12                                            0.000000   \n",
       "                          17                                           -0.731520   \n",
       "                          18                                            0.000000   \n",
       "\n",
       "                                 (F3amplitudeLogRelF0_sma3nz_de_de, median)  \\\n",
       "video_name                diapo                                               \n",
       "Test_pour_AFPA            1                                             0.0   \n",
       "                          8                                             0.0   \n",
       "                          9                                             0.0   \n",
       "                          10                                            0.0   \n",
       "                          11                                            0.0   \n",
       "...                                                                     ...   \n",
       "WIN_20210417_14_53_12_Pro 10                                            0.0   \n",
       "                          11                                            0.0   \n",
       "                          12                                            0.0   \n",
       "                          17                                            0.0   \n",
       "                          18                                            0.0   \n",
       "\n",
       "                                 (F3amplitudeLogRelF0_sma3nz_de_de, std)  \\\n",
       "video_name                diapo                                            \n",
       "Test_pour_AFPA            1                                     8.210914   \n",
       "                          8                                    21.556528   \n",
       "                          9                                    19.785368   \n",
       "                          10                                   18.762260   \n",
       "                          11                                   19.736843   \n",
       "...                                                                  ...   \n",
       "WIN_20210417_14_53_12_Pro 10                                   16.854526   \n",
       "                          11                                   19.730021   \n",
       "                          12                                    8.419112   \n",
       "                          17                                   18.815206   \n",
       "                          18                                    4.080975   \n",
       "\n",
       "                                 (F3amplitudeLogRelF0_sma3nz_de_de, mean)  \\\n",
       "video_name                diapo                                             \n",
       "Test_pour_AFPA            1                                 -6.270232e-18   \n",
       "                          8                                  2.415845e-17   \n",
       "                          9                                 -3.301512e-17   \n",
       "                          10                                 8.702810e-03   \n",
       "                          11                                -6.073836e-03   \n",
       "...                                                                   ...   \n",
       "WIN_20210417_14_53_12_Pro 10                                -4.242046e-18   \n",
       "                          11                                 9.621933e-18   \n",
       "                          12                                 2.647985e-18   \n",
       "                          17                                -6.615398e-17   \n",
       "                          18                                 0.000000e+00   \n",
       "\n",
       "                                 (F3amplitudeLogRelF0_sma3nz_de_de, percentil75)  \\\n",
       "video_name                diapo                                                    \n",
       "Test_pour_AFPA            1                                             0.000000   \n",
       "                          8                                             0.485107   \n",
       "                          9                                             0.193978   \n",
       "                          10                                            0.000000   \n",
       "                          11                                            0.449439   \n",
       "...                                                                          ...   \n",
       "WIN_20210417_14_53_12_Pro 10                                            0.000000   \n",
       "                          11                                            0.000000   \n",
       "                          12                                            0.000000   \n",
       "                          17                                            0.753908   \n",
       "                          18                                            0.000000   \n",
       "\n",
       "                                 (F3amplitudeLogRelF0_sma3nz_de_de, skew)  \\\n",
       "video_name                diapo                                             \n",
       "Test_pour_AFPA            1                                     -0.448768   \n",
       "                          8                                      0.023731   \n",
       "                          9                                      0.180785   \n",
       "                          10                                     0.191598   \n",
       "                          11                                     0.074909   \n",
       "...                                                                   ...   \n",
       "WIN_20210417_14_53_12_Pro 10                                    -0.110385   \n",
       "                          11                                    -0.007796   \n",
       "                          12                                    -1.313023   \n",
       "                          17                                     0.199953   \n",
       "                          18                                    -6.435661   \n",
       "\n",
       "                                 (F3amplitudeLogRelF0_sma3nz_de_de, min)  \\\n",
       "video_name                diapo                                            \n",
       "Test_pour_AFPA            1                                  -133.887694   \n",
       "                          8                                  -158.937280   \n",
       "                          9                                  -161.495940   \n",
       "                          10                                 -160.932650   \n",
       "                          11                                 -158.581520   \n",
       "...                                                                  ...   \n",
       "WIN_20210417_14_53_12_Pro 10                                 -295.940550   \n",
       "                          11                                 -160.083260   \n",
       "                          12                                 -144.071920   \n",
       "                          17                                 -146.911680   \n",
       "                          18                                 -129.773418   \n",
       "\n",
       "                                 Stagiaire  Femme  \n",
       "video_name                diapo                    \n",
       "Test_pour_AFPA            1            1.0    0.0  \n",
       "                          8            1.0    0.0  \n",
       "                          9            1.0    0.0  \n",
       "                          10           1.0    0.0  \n",
       "                          11           1.0    0.0  \n",
       "...                                    ...    ...  \n",
       "WIN_20210417_14_53_12_Pro 10           1.0    1.0  \n",
       "                          11           1.0    1.0  \n",
       "                          12           1.0    1.0  \n",
       "                          17           1.0    1.0  \n",
       "                          18           1.0    1.0  \n",
       "\n",
       "[240 rows x 623 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th></th>\n      <th>(Loudness_sma3, kurtosis)</th>\n      <th>(Loudness_sma3, max)</th>\n      <th>(Loudness_sma3, percentil25)</th>\n      <th>(Loudness_sma3, median)</th>\n      <th>(Loudness_sma3, std)</th>\n      <th>(Loudness_sma3, mean)</th>\n      <th>(Loudness_sma3, percentil75)</th>\n      <th>(Loudness_sma3, skew)</th>\n      <th>(Loudness_sma3, min)</th>\n      <th>(alphaRatio_sma3, kurtosis)</th>\n      <th>...</th>\n      <th>(F3amplitudeLogRelF0_sma3nz_de_de, max)</th>\n      <th>(F3amplitudeLogRelF0_sma3nz_de_de, percentil25)</th>\n      <th>(F3amplitudeLogRelF0_sma3nz_de_de, median)</th>\n      <th>(F3amplitudeLogRelF0_sma3nz_de_de, std)</th>\n      <th>(F3amplitudeLogRelF0_sma3nz_de_de, mean)</th>\n      <th>(F3amplitudeLogRelF0_sma3nz_de_de, percentil75)</th>\n      <th>(F3amplitudeLogRelF0_sma3nz_de_de, skew)</th>\n      <th>(F3amplitudeLogRelF0_sma3nz_de_de, min)</th>\n      <th>Stagiaire</th>\n      <th>Femme</th>\n    </tr>\n    <tr>\n      <th>video_name</th>\n      <th>diapo</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th rowspan=\"5\" valign=\"top\">Test_pour_AFPA</th>\n      <th>1</th>\n      <td>195.631236</td>\n      <td>3.545050</td>\n      <td>0.114812</td>\n      <td>0.119039</td>\n      <td>0.130805</td>\n      <td>0.136717</td>\n      <td>0.124505</td>\n      <td>12.240252</td>\n      <td>0.083114</td>\n      <td>35.764880</td>\n      <td>...</td>\n      <td>131.8622</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>8.210914</td>\n      <td>-6.270232e-18</td>\n      <td>0.000000</td>\n      <td>-0.448768</td>\n      <td>-133.887694</td>\n      <td>1.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>1.922854</td>\n      <td>2.867280</td>\n      <td>0.117015</td>\n      <td>0.282706</td>\n      <td>0.424739</td>\n      <td>0.460516</td>\n      <td>0.711492</td>\n      <td>1.370343</td>\n      <td>0.100229</td>\n      <td>0.110346</td>\n      <td>...</td>\n      <td>143.5802</td>\n      <td>-0.575755</td>\n      <td>0.0</td>\n      <td>21.556528</td>\n      <td>2.415845e-17</td>\n      <td>0.485107</td>\n      <td>0.023731</td>\n      <td>-158.937280</td>\n      <td>1.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>2.268561</td>\n      <td>3.393920</td>\n      <td>0.112834</td>\n      <td>0.209026</td>\n      <td>0.383514</td>\n      <td>0.411576</td>\n      <td>0.639661</td>\n      <td>1.420768</td>\n      <td>0.099458</td>\n      <td>0.410082</td>\n      <td>...</td>\n      <td>151.9159</td>\n      <td>-0.272000</td>\n      <td>0.0</td>\n      <td>19.785368</td>\n      <td>-3.301512e-17</td>\n      <td>0.193978</td>\n      <td>0.180785</td>\n      <td>-161.495940</td>\n      <td>1.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>10.863511</td>\n      <td>5.028640</td>\n      <td>0.111221</td>\n      <td>0.148684</td>\n      <td>0.391520</td>\n      <td>0.382675</td>\n      <td>0.590052</td>\n      <td>2.289813</td>\n      <td>0.099492</td>\n      <td>0.166996</td>\n      <td>...</td>\n      <td>141.5019</td>\n      <td>-0.215863</td>\n      <td>0.0</td>\n      <td>18.762260</td>\n      <td>8.702810e-03</td>\n      <td>0.000000</td>\n      <td>0.191598</td>\n      <td>-160.932650</td>\n      <td>1.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>9.862057</td>\n      <td>5.151010</td>\n      <td>0.113637</td>\n      <td>0.252318</td>\n      <td>0.381967</td>\n      <td>0.408419</td>\n      <td>0.605844</td>\n      <td>2.060058</td>\n      <td>0.098327</td>\n      <td>-0.160992</td>\n      <td>...</td>\n      <td>154.1847</td>\n      <td>-0.406947</td>\n      <td>0.0</td>\n      <td>19.736843</td>\n      <td>-6.073836e-03</td>\n      <td>0.449439</td>\n      <td>0.074909</td>\n      <td>-158.581520</td>\n      <td>1.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th rowspan=\"5\" valign=\"top\">WIN_20210417_14_53_12_Pro</th>\n      <th>10</th>\n      <td>2.940143</td>\n      <td>3.264950</td>\n      <td>0.001104</td>\n      <td>0.013893</td>\n      <td>0.464786</td>\n      <td>0.301682</td>\n      <td>0.547356</td>\n      <td>1.707042</td>\n      <td>0.001034</td>\n      <td>0.025470</td>\n      <td>...</td>\n      <td>201.0000</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>16.854526</td>\n      <td>-4.242046e-18</td>\n      <td>0.000000</td>\n      <td>-0.110385</td>\n      <td>-295.940550</td>\n      <td>1.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>1.568983</td>\n      <td>2.660928</td>\n      <td>0.001126</td>\n      <td>0.081050</td>\n      <td>0.431815</td>\n      <td>0.330021</td>\n      <td>0.586716</td>\n      <td>1.397632</td>\n      <td>0.001034</td>\n      <td>-0.130052</td>\n      <td>...</td>\n      <td>143.9756</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>19.730021</td>\n      <td>9.621933e-18</td>\n      <td>0.000000</td>\n      <td>-0.007796</td>\n      <td>-160.083260</td>\n      <td>1.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>4.232695</td>\n      <td>0.384004</td>\n      <td>0.014089</td>\n      <td>0.029460</td>\n      <td>0.038861</td>\n      <td>0.041404</td>\n      <td>0.058949</td>\n      <td>1.654525</td>\n      <td>0.001034</td>\n      <td>0.938287</td>\n      <td>...</td>\n      <td>116.6289</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>8.419112</td>\n      <td>2.647985e-18</td>\n      <td>0.000000</td>\n      <td>-1.313023</td>\n      <td>-144.071920</td>\n      <td>1.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>0.669043</td>\n      <td>3.344785</td>\n      <td>0.006968</td>\n      <td>0.488653</td>\n      <td>0.708703</td>\n      <td>0.651603</td>\n      <td>1.049473</td>\n      <td>1.121390</td>\n      <td>0.001034</td>\n      <td>0.245458</td>\n      <td>...</td>\n      <td>135.7129</td>\n      <td>-0.731520</td>\n      <td>0.0</td>\n      <td>18.815206</td>\n      <td>-6.615398e-17</td>\n      <td>0.753908</td>\n      <td>0.199953</td>\n      <td>-146.911680</td>\n      <td>1.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>-0.914318</td>\n      <td>0.203776</td>\n      <td>0.001236</td>\n      <td>0.034392</td>\n      <td>0.037630</td>\n      <td>0.041692</td>\n      <td>0.075999</td>\n      <td>0.487773</td>\n      <td>0.001034</td>\n      <td>0.822559</td>\n      <td>...</td>\n      <td>68.0983</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>4.080975</td>\n      <td>0.000000e+00</td>\n      <td>0.000000</td>\n      <td>-6.435661</td>\n      <td>-129.773418</td>\n      <td>1.0</td>\n      <td>1.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>240 rows × 623 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.fillna(0)"
   ]
  },
  {
   "source": [
    "### Leave one interview out\n",
    "#### All diapos"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "diapo_selection = '_all'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import LeaveOneGroupOut\n",
    "\n",
    "models_list = [RandomForestClassifier(random_state = 42, n_jobs=-1)]\n",
    "parameters_list = [\n",
    "                {'n_estimators': [50, 100, 150], 'max_depth':[5, 10, 15, 20, 25], 'class_weight':[None,'balanced']}\n",
    "                ]\n",
    "groups = X.reset_index()['video_name']\n",
    "loo = LeaveOneGroupOut()\n",
    "cv_loo = loo.split(X, y, groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Fitting 30 folds for each of 20 candidates, totalling 600 fits\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  52 tasks      | elapsed:    1.2s\n",
      "[Parallel(n_jobs=-1)]: Done 352 tasks      | elapsed:    6.8s\n",
      "[Parallel(n_jobs=-1)]: Done 600 out of 600 | elapsed:   11.3s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "Best estimator LogisticRegression(C=0.01, multi_class='multinomial', random_state=42)\n",
      "Best results 0.3\n",
      "Best params {'C': 0.01, 'class_weight': None}\n",
      "accuracy (mean, std) 0.3 0.45825756949558394\n",
      "f1 (mean, std) 0.3 0.45825756949558394\n",
      "balanced accuracy (mean, std) 0.3 0.45825756949558394\n",
      "precision (mean, std) 0.3 0.45825756949558394\n",
      "recall (mean, std) 0.3 0.45825756949558394\n",
      "\n",
      "Fitting 30 folds for each of 80 candidates, totalling 2400 fits\n",
      "[Parallel(n_jobs=-1)]: Done  56 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=-1)]: Done 656 tasks      | elapsed:    5.1s\n",
      "[Parallel(n_jobs=-1)]: Done 1656 tasks      | elapsed:   12.7s\n",
      "[Parallel(n_jobs=-1)]: Done 2400 out of 2400 | elapsed:   18.3s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "Best estimator Pipeline(steps=[('pca', PCA(n_components=4)),\n",
      "                ('logistic',\n",
      "                 LogisticRegression(C=0.05, class_weight='balanced',\n",
      "                                    multi_class='multinomial',\n",
      "                                    random_state=42))])\n",
      "Best results 0.3333333333333333\n",
      "Best params {'logistic__C': 0.05, 'logistic__class_weight': 'balanced', 'pca__n_components': 4}\n",
      "accuracy (mean, std) 0.3333333333333333 0.4714045207910317\n",
      "f1 (mean, std) 0.3333333333333333 0.4714045207910317\n",
      "balanced accuracy (mean, std) 0.3333333333333333 0.4714045207910317\n",
      "precision (mean, std) 0.3333333333333333 0.4714045207910317\n",
      "recall (mean, std) 0.3333333333333333 0.4714045207910317\n",
      "\n",
      "Fitting 30 folds for each of 44 candidates, totalling 1320 fits\n",
      "[Parallel(n_jobs=-1)]: Done  56 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=-1)]: Done 656 tasks      | elapsed:    3.1s\n",
      "[Parallel(n_jobs=-1)]: Done 1305 out of 1320 | elapsed:    5.9s remaining:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done 1320 out of 1320 | elapsed:    6.0s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "Best estimator KNeighborsClassifier(n_neighbors=8, p=1)\n",
      "Best results 0.4\n",
      "Best params {'n_neighbors': 8, 'p': 1, 'weights': 'uniform'}\n",
      "accuracy (mean, std) 0.4 0.4898979485566357\n",
      "f1 (mean, std) 0.4 0.4898979485566357\n",
      "balanced accuracy (mean, std) 0.4 0.4898979485566357\n",
      "precision (mean, std) 0.4 0.4898979485566357\n",
      "recall (mean, std) 0.4 0.4898979485566357\n",
      "\n",
      "Fitting 30 folds for each of 176 candidates, totalling 5280 fits\n",
      "[Parallel(n_jobs=-1)]: Done  56 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=-1)]: Done 656 tasks      | elapsed:    3.5s\n",
      "[Parallel(n_jobs=-1)]: Done 1656 tasks      | elapsed:    8.7s\n",
      "[Parallel(n_jobs=-1)]: Done 3056 tasks      | elapsed:   15.9s\n",
      "[Parallel(n_jobs=-1)]: Done 4856 tasks      | elapsed:   25.0s\n",
      "[Parallel(n_jobs=-1)]: Done 5280 out of 5280 | elapsed:   27.1s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "Best estimator Pipeline(steps=[('pca', PCA(n_components=1)),\n",
      "                ('knn', KNeighborsClassifier(n_neighbors=20, p=1))])\n",
      "Best results 0.4\n",
      "Best params {'knn__n_neighbors': 20, 'knn__p': 1, 'knn__weights': 'uniform', 'pca__n_components': 1}\n",
      "accuracy (mean, std) 0.4 0.4898979485566357\n",
      "f1 (mean, std) 0.4 0.4898979485566357\n",
      "balanced accuracy (mean, std) 0.4 0.4898979485566357\n",
      "precision (mean, std) 0.4 0.4898979485566357\n",
      "recall (mean, std) 0.4 0.4898979485566357\n",
      "\n",
      "Fitting 30 folds for each of 56 candidates, totalling 1680 fits\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    1.4s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:   10.6s\n",
      "[Parallel(n_jobs=-1)]: Done 434 tasks      | elapsed:   26.7s\n",
      "[Parallel(n_jobs=-1)]: Done 784 tasks      | elapsed:   48.9s\n",
      "[Parallel(n_jobs=-1)]: Done 1234 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done 1680 out of 1680 | elapsed:  1.8min finished\n",
      "Best estimator RandomForestClassifier(class_weight='balanced', max_depth=5, n_estimators=50,\n",
      "                       n_jobs=-1, random_state=42)\n",
      "Best results 0.36666666666666664\n",
      "Best params {'class_weight': 'balanced', 'max_depth': 5, 'n_estimators': 50}\n",
      "accuracy (mean, std) 0.36666666666666664 0.48189440982669857\n",
      "f1 (mean, std) 0.36666666666666664 0.48189440982669857\n",
      "balanced accuracy (mean, std) 0.36666666666666664 0.48189440982669857\n",
      "precision (mean, std) 0.36666666666666664 0.48189440982669857\n",
      "recall (mean, std) 0.36666666666666664 0.48189440982669857\n",
      "\n",
      "f1_score (weighted) 0.3114543114543115\n",
      "accuracy 0.4\n"
     ]
    }
   ],
   "source": [
    "best_result, y_predict, y_predict_proba, result_list = runGridSearchClassifiers(X, y, cv_loo, models_list, parameters_list, \n",
    "                                                                output_predict=True, n_jobs=-1, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving predictions\n",
    "df_ypredict = pd.concat([X.reset_index()[['video_name','diapo']],pd.DataFrame(y_predict, columns=['ypredict'])],axis=1)\n",
    "df_ypredict.to_csv('ypredict_' + features + '_diapo' + diapo_selection + '.csv')"
   ]
  },
  {
   "source": [
    "### Audio diapos only"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "diapo_selection = '_audio_only'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import LeaveOneGroupOut\n",
    "\n",
    "models_list = [RandomForestClassifier(random_state = 42, n_jobs=-1)]\n",
    "parameters_list = [\n",
    "                {'n_estimators': [50, 100, 150], 'max_depth':[ 5, 10, 15, 20, 25], 'class_weight':[None,'balanced']}\n",
    "                ]\n",
    "groups = X_audio.reset_index()['video_name']\n",
    "loo = LeaveOneGroupOut()\n",
    "cv_loo = loo.split(X_audio, y_audio, groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Fitting 30 folds for each of 30 candidates, totalling 900 fits\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    4.2s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:   17.3s\n",
      "[Parallel(n_jobs=-1)]: Done 434 tasks      | elapsed:   37.9s\n",
      "[Parallel(n_jobs=-1)]: Done 784 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done 900 out of 900 | elapsed:  1.3min finished\n",
      "Best estimator RandomForestClassifier(max_depth=5, n_estimators=50, n_jobs=-1, random_state=42)\n",
      "Best results 0.4660158730158729\n",
      "Best params {'class_weight': None, 'max_depth': 5, 'n_estimators': 50}\n",
      "accuracy (mean, std) 0.46 0.248461935381123\n",
      "f1 (mean, std) 0.4660158730158729 0.2799987142887613\n",
      "balanced accuracy (mean, std) 0.4677777777777778 0.2460966888174515\n",
      "precision (mean, std) 0.5954444444444446 0.36782794219815385\n",
      "recall (mean, std) 0.46 0.248461935381123\n",
      "\n",
      "f1_score (weighted) 0.4485365136980382\n",
      "accuracy 0.46\n"
     ]
    }
   ],
   "source": [
    "best_result, y_predict,y_predict_proba, result_list = runGridSearchClassifiers(X_audio, y_audio, cv_loo, models_list, parameters_list, output_predict=True, n_jobs=-1, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ypredict = pd.concat([X_audio.reset_index()[['video_name','diapo']],pd.DataFrame(y_predict, columns=['ypredict'])],axis=1)\n",
    "df_ypredict.to_csv('ypredict_' + features + '_diapo' + diapo_selection + '.csv')"
   ]
  },
  {
   "source": [
    "## Stress global\n",
    "### All diapos"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "diapo_selection = '_all' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ypredict = pd.read_csv('ypredict_' + features + '_diapo' + diapo_selection + '.csv')\n",
    "df_ypredict = df_ypredict.drop(df_ypredict.columns[0],axis=1)\n",
    "df_ypredict.columns = ['video_name','diapo','ypredict']\n",
    "ypredict_stress_diapo = df_ypredict.pivot_table(values='ypredict', columns='diapo',index='video_name',aggfunc='mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_annotations_stress_diapo = df_total.pivot_table(values='stress', index='video_name',columns='diapo', aggfunc='mean')\n",
    "#df_annotations_stress_global = df_total.pivot_table(values='stress_global', index='video_name', aggfunc='mean')\n",
    "#df_annotations_stress = df_annotations_stress_diapo.merge(df_annotations_stress_global, on='video_name')\n",
    "#df_annotations_stress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_annotations_stress = pd.read_csv('annotations.csv')"
   ]
  },
  {
   "source": [
    "#### En utilisant les annotations comme X"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "models_list = [\n",
    "                LogisticRegression(multi_class='multinomial', fit_intercept=True, random_state=42),\n",
    "                KNeighborsClassifier(),\n",
    "                RandomForestClassifier(random_state = 42, n_jobs=-1)\n",
    "                ]\n",
    "\n",
    "parameters_list = [\n",
    "                    {'C': [0.01, 0.05, 0.1, 0.5, 1, 2], 'class_weight' : [None, 'balanced']},\n",
    "                    {'n_neighbors': [4, 5, 6, 7, 8, 9, 10, 11, 12,  15, 20], 'weights' : ['uniform', 'distance'], 'p': [1, 2]},\n",
    "                    {'n_estimators': [50, 100, 150, 200], 'max_depth':[3, 4, 5, 6, 10, 15, 20], 'class_weight':[None,'balanced']}\n",
    "                    ]\n",
    "X = df_annotations_stress.iloc[:,:-1].set_index('video_name')\n",
    "y = df_annotations_stress.iloc[:,-1]\n",
    "cv = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  60 out of  60 | elapsed:    0.3s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "Best estimator LogisticRegression(C=0.1, multi_class='multinomial', random_state=42)\n",
      "Best results 0.7651587301587301\n",
      "Best params {'C': 0.1, 'class_weight': None}\n",
      "accuracy (mean, std) 0.8 0.0666666666666667\n",
      "f1 (mean, std) 0.7651587301587301 0.11176124986563704\n",
      "balanced accuracy (mean, std) 0.8 0.0666666666666667\n",
      "precision (mean, std) 0.8016666666666665 0.16758635142870432\n",
      "recall (mean, std) 0.8 0.0666666666666667\n",
      "\n",
      "Fitting 5 folds for each of 44 candidates, totalling 220 fits\n",
      "[Parallel(n_jobs=-1)]: Done  58 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=-1)]: Done 220 out of 220 | elapsed:    0.6s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "Best estimator KNeighborsClassifier(n_neighbors=6, weights='distance')\n",
      "Best results 0.8114285714285714\n",
      "Best params {'n_neighbors': 6, 'p': 2, 'weights': 'distance'}\n",
      "accuracy (mean, std) 0.8333333333333334 0.10540925533894599\n",
      "f1 (mean, std) 0.8114285714285714 0.1285043916946314\n",
      "balanced accuracy (mean, std) 0.8 0.16329931618554522\n",
      "precision (mean, std) 0.8388888888888889 0.15530734164993737\n",
      "recall (mean, std) 0.8333333333333334 0.10540925533894599\n",
      "\n",
      "Fitting 5 folds for each of 56 candidates, totalling 280 fits\n",
      "[Parallel(n_jobs=-1)]: Done  52 tasks      | elapsed:    3.6s\n",
      "[Parallel(n_jobs=-1)]: Done 224 tasks      | elapsed:   13.4s\n",
      "Best estimator RandomForestClassifier(class_weight='balanced', max_depth=4, n_jobs=-1,\n",
      "                       random_state=42)\n",
      "Best results 0.7501587301587301\n",
      "Best params {'class_weight': 'balanced', 'max_depth': 4, 'n_estimators': 100}\n",
      "accuracy (mean, std) 0.7666666666666666 0.13333333333333336\n",
      "f1 (mean, std) 0.7501587301587301 0.14529697826233098\n",
      "balanced accuracy (mean, std) 0.7444444444444445 0.16703662642636563\n",
      "precision (mean, std) 0.7861111111111111 0.16282612099725385\n",
      "recall (mean, std) 0.7666666666666666 0.13333333333333336\n",
      "\n",
      "f1_score (weighted) 0.8297410192147034\n",
      "accuracy 0.8333333333333334\n",
      "[Parallel(n_jobs=-1)]: Done 280 out of 280 | elapsed:   16.8s finished\n"
     ]
    }
   ],
   "source": [
    "best_result, y_predict, y_predict_proba, result_list = runGridSearchClassifiers(X, y, cv, models_list, parameters_list, \n",
    "                                                                output_predict=True, n_jobs=-1, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Accuracy 0.36666666666666664\nF1 0.3095238095238095\nBalanced accuracy 0.33888888888888885\nPrecision 0.27777777777777773\nRecall 0.36666666666666664\n"
     ]
    }
   ],
   "source": [
    "ypredict_stress_global = best_result['best_estimator'].predict(ypredict_stress_diapo)\n",
    "from sklearn.metrics import accuracy_score, f1_score, balanced_accuracy_score, precision_score, recall_score\n",
    "print('Accuracy',accuracy_score(y.values,ypredict_stress_global))\n",
    "print('F1',f1_score(y.values,ypredict_stress_global, average='weighted'))\n",
    "print('Balanced accuracy',balanced_accuracy_score(y.values,ypredict_stress_global))\n",
    "print('Precision',precision_score(y.values,ypredict_stress_global, average='weighted'))\n",
    "print('Recall',recall_score(y.values,ypredict_stress_global, average='weighted'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                         video_name  stress_global  predicted_stress_global\n",
       "0                    Test_pour_AFPA            1.0                      1.0\n",
       "1                           Video_1            0.0                      1.0\n",
       "2         WIN_20210323_19_17_40_Pro            1.0                      0.0\n",
       "3         WIN_20210329_10_16_02_Pro            1.0                      1.0\n",
       "4         WIN_20210330_13_10_29_Pro            0.0                      0.0\n",
       "5         WIN_20210331_21_22_52_Pro            1.0                      1.0\n",
       "6         WIN_20210402_14_27_50_Pro            1.0                      1.0\n",
       "7         WIN_20210402_19_04_53_Pro            2.0                      1.0\n",
       "8         WIN_20210403_18_49_15_Pro            2.0                      1.0\n",
       "9         WIN_20210404_10_58_27_Pro            1.0                      1.0\n",
       "10        WIN_20210404_21_41_12_Pro            0.0                      1.0\n",
       "11        WIN_20210405_15_09_16_Pro            1.0                      0.0\n",
       "12        WIN_20210406_15_06_15_Pro            2.0                      0.0\n",
       "13        WIN_20210406_18_35_52_Pro            0.0                      0.0\n",
       "14        WIN_20210406_18_49_10_Pro            1.0                      1.0\n",
       "15        WIN_20210406_21_05_52_Pro            2.0                      0.0\n",
       "16        WIN_20210407_09_04_05_Pro            2.0                      0.0\n",
       "17  WIN_20210407_14_54_56_Pro_edit2            0.0                      1.0\n",
       "18        WIN_20210408_11_48_58_Pro            2.0                      1.0\n",
       "19        WIN_20210408_14_00_44_Pro            0.0                      0.0\n",
       "20        WIN_20210408_14_02_19_Pro            0.0                      1.0\n",
       "21        WIN_20210408_14_11_32_Pro            2.0                      1.0\n",
       "22        WIN_20210408_15_20_51_Pro            0.0                      1.0\n",
       "23        WIN_20210408_16_04_32_Pro            0.0                      0.0\n",
       "24        WIN_20210409_10_26_11_Pro            0.0                      0.0\n",
       "25        WIN_20210413_15_38_01_Pro            1.0                      0.0\n",
       "26        WIN_20210414_06_24_52_Pro            2.0                      1.0\n",
       "27        WIN_20210415_15_41_24_Pro            0.0                      1.0\n",
       "28        WIN_20210416_08_06_54_Pro            1.0                      0.0\n",
       "29        WIN_20210417_14_53_12_Pro            0.0                      1.0"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>video_name</th>\n      <th>stress_global</th>\n      <th>predicted_stress_global</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Test_pour_AFPA</td>\n      <td>1.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Video_1</td>\n      <td>0.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>WIN_20210323_19_17_40_Pro</td>\n      <td>1.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>WIN_20210329_10_16_02_Pro</td>\n      <td>1.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>WIN_20210330_13_10_29_Pro</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>WIN_20210331_21_22_52_Pro</td>\n      <td>1.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>WIN_20210402_14_27_50_Pro</td>\n      <td>1.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>WIN_20210402_19_04_53_Pro</td>\n      <td>2.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>WIN_20210403_18_49_15_Pro</td>\n      <td>2.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>WIN_20210404_10_58_27_Pro</td>\n      <td>1.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>WIN_20210404_21_41_12_Pro</td>\n      <td>0.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>WIN_20210405_15_09_16_Pro</td>\n      <td>1.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>WIN_20210406_15_06_15_Pro</td>\n      <td>2.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>WIN_20210406_18_35_52_Pro</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>WIN_20210406_18_49_10_Pro</td>\n      <td>1.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>WIN_20210406_21_05_52_Pro</td>\n      <td>2.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>WIN_20210407_09_04_05_Pro</td>\n      <td>2.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>WIN_20210407_14_54_56_Pro_edit2</td>\n      <td>0.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>WIN_20210408_11_48_58_Pro</td>\n      <td>2.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>WIN_20210408_14_00_44_Pro</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>WIN_20210408_14_02_19_Pro</td>\n      <td>0.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>WIN_20210408_14_11_32_Pro</td>\n      <td>2.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>WIN_20210408_15_20_51_Pro</td>\n      <td>0.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>WIN_20210408_16_04_32_Pro</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>24</th>\n      <td>WIN_20210409_10_26_11_Pro</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>25</th>\n      <td>WIN_20210413_15_38_01_Pro</td>\n      <td>1.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>26</th>\n      <td>WIN_20210414_06_24_52_Pro</td>\n      <td>2.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>27</th>\n      <td>WIN_20210415_15_41_24_Pro</td>\n      <td>0.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>28</th>\n      <td>WIN_20210416_08_06_54_Pro</td>\n      <td>1.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>29</th>\n      <td>WIN_20210417_14_53_12_Pro</td>\n      <td>0.0</td>\n      <td>1.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 24
    }
   ],
   "source": [
    "pd.concat([X.reset_index().iloc[:,0],y, pd.DataFrame(ypredict_stress_global,columns=['predicted_stress_global'])],axis=1)"
   ]
  },
  {
   "source": [
    "#### En utilisant les prédictions comme annotations"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import LeaveOneGroupOut\n",
    "\n",
    "models_list = [\n",
    "                LogisticRegression(multi_class='multinomial', fit_intercept=True, random_state=42),\n",
    "                KNeighborsClassifier(),\n",
    "                RandomForestClassifier(random_state = 42, n_jobs=-1)\n",
    "                ]\n",
    "\n",
    "parameters_list = [\n",
    "                    {'C': [0.01, 0.05, 0.1, 0.5, 1, 2, 3, 4 , 5, 10], 'class_weight' : [None, 'balanced']},\n",
    "                    {'n_neighbors': [4, 5, 6, 7, 8, 9, 10, 11, 12,  15, 20], 'weights' : ['uniform', 'distance'], 'p': [1, 2]},\n",
    "                    {'n_estimators': [50, 100, 150, 200], 'max_depth':[3, 4, 5, 6, 10, 15, 20], 'class_weight':[None,'balanced']}\n",
    "                    ]\n",
    "X = ypredict_stress_diapo\n",
    "y = df_annotations_stress.iloc[:,-1]\n",
    "groups = X.reset_index()['video_name']\n",
    "loo = LeaveOneGroupOut()\n",
    "cv_loo = loo.split(X, y, groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    2.4s\n",
      "[Parallel(n_jobs=-1)]: Done  85 out of 100 | elapsed:    2.7s remaining:    0.5s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    2.7s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "Best estimator LogisticRegression(C=10, multi_class='multinomial', random_state=42)\n",
      "Best results 0.5098412698412699\n",
      "Best params {'C': 10, 'class_weight': None}\n",
      "accuracy (mean, std) 0.5666666666666667 0.16996731711975951\n",
      "f1 (mean, std) 0.5098412698412699 0.20862095036746608\n",
      "balanced accuracy (mean, std) 0.5888888888888889 0.16329931618554522\n",
      "precision (mean, std) 0.5055555555555555 0.2631715396072669\n",
      "recall (mean, std) 0.5666666666666667 0.16996731711975951\n",
      "\n",
      "Fitting 5 folds for each of 44 candidates, totalling 220 fits\n",
      "[Parallel(n_jobs=-1)]: Done  56 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=-1)]: Done 220 out of 220 | elapsed:    0.7s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "Best estimator KNeighborsClassifier(n_neighbors=8)\n",
      "Best results 0.36\n",
      "Best params {'n_neighbors': 8, 'p': 2, 'weights': 'uniform'}\n",
      "accuracy (mean, std) 0.4 0.08164965809277261\n",
      "f1 (mean, std) 0.36 0.024944382578492925\n",
      "balanced accuracy (mean, std) 0.4444444444444445 0.060858061945018464\n",
      "precision (mean, std) 0.3555555555555555 0.04444444444444444\n",
      "recall (mean, std) 0.4 0.08164965809277261\n",
      "\n",
      "Fitting 5 folds for each of 56 candidates, totalling 280 fits\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    2.3s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:   11.9s\n",
      "[Parallel(n_jobs=-1)]: Done 280 out of 280 | elapsed:   18.2s finished\n",
      "Best estimator RandomForestClassifier(class_weight='balanced', max_depth=6, n_estimators=150,\n",
      "                       n_jobs=-1, random_state=42)\n",
      "Best results 0.5019047619047619\n",
      "Best params {'class_weight': 'balanced', 'max_depth': 6, 'n_estimators': 150}\n",
      "accuracy (mean, std) 0.5333333333333333 0.19436506316151003\n",
      "f1 (mean, std) 0.5019047619047619 0.20787082447381236\n",
      "balanced accuracy (mean, std) 0.5333333333333333 0.22388268532899872\n",
      "precision (mean, std) 0.5138888888888888 0.2424794760310577\n",
      "recall (mean, std) 0.5333333333333333 0.19436506316151003\n",
      "\n",
      "f1_score (weighted) 0.5525676937441644\n",
      "accuracy 0.5666666666666667\n"
     ]
    }
   ],
   "source": [
    "best_result, y_predict, y_predict_proba, result_list = runGridSearchClassifiers(X, y, 5, models_list, parameters_list, \n",
    "                                                                output_predict=True, n_jobs=-1, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'best_estimator': LogisticRegression(C=10, multi_class='multinomial', random_state=42),\n",
       " 'best_score': 0.5098412698412699,\n",
       " 'best_params': {'C': 10, 'class_weight': None},\n",
       " 'mean_test_f1_score': 0.5098412698412699,\n",
       " 'std_test_f1_score': 0.20862095036746608,\n",
       " 'mean_test_accuracy_score': 0.5666666666666667,\n",
       " 'std_test_accuracy_score': 0.16996731711975951,\n",
       " 'mean_test_balanced_accuracy_score': 0.5888888888888889,\n",
       " 'std_test_balanced_accuracy_score': 0.16329931618554522,\n",
       " 'mean_test_precision': 0.5055555555555555,\n",
       " 'std_test_precision': 0.2631715396072669,\n",
       " 'mean_test_recall': 0.5666666666666667,\n",
       " 'std_test_recall': 0.16996731711975951}"
      ]
     },
     "metadata": {},
     "execution_count": 19
    }
   ],
   "source": [
    "best_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ypredict = pd.concat([X.reset_index()[['video_name']],pd.DataFrame(y_predict, columns=['ypredict'])],axis=1)\n",
    "df_ypredict.to_csv('ypredict_' + features + '_global' + diapo_selection + '.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ypredict = pd.concat([X.reset_index()[['video_name']],pd.DataFrame(y_predict_proba, columns=['predict_0','predict_1','predict_2'])],axis=1)\n",
    "df_ypredict.to_csv('ypredict_' + features + '_global_proba' + diapo_selection + '.csv')"
   ]
  },
  {
   "source": [
    "### Audio diapos only"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "diapo_selection = '_audio_only'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ypredict = pd.read_csv('ypredict_' + features + '_diapo' + diapo_selection + '.csv')\n",
    "df_ypredict = df_ypredict.drop(df_ypredict.columns[0],axis=1)\n",
    "df_ypredict.columns = ['video_name','diapo','ypredict']\n",
    "ypredict_stress_diapo = df_ypredict.pivot_table(values='ypredict', columns='diapo',index='video_name',aggfunc='mean')"
   ]
  },
  {
   "source": [
    "#### En utilisant les annotations comme X"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "models_list = [\n",
    "                LogisticRegression(multi_class='multinomial', fit_intercept=True, random_state=42),\n",
    "                KNeighborsClassifier(),\n",
    "                RandomForestClassifier(random_state = 42, n_jobs=-1)\n",
    "                ]\n",
    "\n",
    "parameters_list = [\n",
    "                    {'C': [0.01, 0.05, 0.1, 0.5, 1, 2], 'class_weight' : [None, 'balanced']},\n",
    "                    {'n_neighbors': [4, 5, 6, 7, 8, 9, 10, 11, 12,  15, 20], 'weights' : ['uniform', 'distance'], 'p': [1, 2]},\n",
    "                    {'n_estimators': [50, 100, 150, 200], 'max_depth':[3, 4, 5, 6, 10, 15, 20], 'class_weight':[None,'balanced']}\n",
    "                    ]\n",
    "X = df_annotations_stress[['video_name','8','9','10','11','17','stress_global']].iloc[:,:-1].set_index('video_name')\n",
    "y = df_annotations_stress.iloc[:,-1]\n",
    "cv = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  45 out of  60 | elapsed:    0.2s remaining:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done  60 out of  60 | elapsed:    0.3s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "Best estimator LogisticRegression(C=0.1, class_weight='balanced', multi_class='multinomial',\n",
      "                   random_state=42)\n",
      "Best results 0.7092063492063492\n",
      "Best params {'C': 0.1, 'class_weight': 'balanced'}\n",
      "accuracy (mean, std) 0.7666666666666667 0.08164965809277264\n",
      "f1 (mean, std) 0.7092063492063492 0.134722169623853\n",
      "balanced accuracy (mean, std) 0.7666666666666667 0.08164965809277264\n",
      "precision (mean, std) 0.7166666666666666 0.20042393341719386\n",
      "recall (mean, std) 0.7666666666666667 0.08164965809277264\n",
      "\n",
      "Fitting 5 folds for each of 44 candidates, totalling 220 fits\n",
      "[Parallel(n_jobs=-1)]: Done  56 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=-1)]: Done 220 out of 220 | elapsed:    0.6s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "Best estimator KNeighborsClassifier(n_neighbors=8, weights='distance')\n",
      "Best results 0.7358730158730158\n",
      "Best params {'n_neighbors': 8, 'p': 2, 'weights': 'distance'}\n",
      "accuracy (mean, std) 0.7666666666666667 0.16996731711975951\n",
      "f1 (mean, std) 0.7358730158730158 0.19420840873059006\n",
      "balanced accuracy (mean, std) 0.7333333333333334 0.2\n",
      "precision (mean, std) 0.7611111111111111 0.20134578082689025\n",
      "recall (mean, std) 0.7666666666666667 0.16996731711975951\n",
      "\n",
      "Fitting 5 folds for each of 56 candidates, totalling 280 fits\n",
      "[Parallel(n_jobs=-1)]: Done  52 tasks      | elapsed:    3.4s\n",
      "[Parallel(n_jobs=-1)]: Done 232 tasks      | elapsed:   14.4s\n",
      "[Parallel(n_jobs=-1)]: Done 280 out of 280 | elapsed:   17.4s finished\n",
      "Best estimator RandomForestClassifier(max_depth=4, n_estimators=150, n_jobs=-1,\n",
      "                       random_state=42)\n",
      "Best results 0.6834920634920635\n",
      "Best params {'class_weight': None, 'max_depth': 4, 'n_estimators': 150}\n",
      "accuracy (mean, std) 0.7 0.12472191289246475\n",
      "f1 (mean, std) 0.6834920634920635 0.13777046282973532\n",
      "balanced accuracy (mean, std) 0.711111111111111 0.12372809695177828\n",
      "precision (mean, std) 0.7527777777777778 0.14917468424552835\n",
      "recall (mean, std) 0.7 0.12472191289246475\n",
      "\n",
      "f1_score (weighted) 0.7541478129713425\n",
      "accuracy 0.7666666666666667\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 3)",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-67971397b53b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m best_result, y_predict, result_list = runGridSearchClassifiers(X, y, cv, models_list, parameters_list, \n\u001b[0m\u001b[1;32m      2\u001b[0m                                                                 output_predict=True, n_jobs=-1, verbose=True)\n",
      "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 3)"
     ]
    }
   ],
   "source": [
    "best_result, y_predict, result_list = runGridSearchClassifiers(X, y, cv, models_list, parameters_list, \n",
    "                                                                output_predict=True, n_jobs=-1, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ypredict_stress_global = best_result['best_estimator'].predict(ypredict_stress_diapo)\n",
    "from sklearn.metrics import accuracy_score, f1_score, balanced_accuracy_score, precision_score, recall_score\n",
    "print('Accuracy',accuracy_score(y.values,ypredict_stress_global))\n",
    "print('F1',f1_score(y.values,ypredict_stress_global, average='weighted'))\n",
    "print('Balanced accuracy',balanced_accuracy_score(y.values,ypredict_stress_global))\n",
    "print('Precision',precision_score(y.values,ypredict_stress_global, average='weighted'))\n",
    "print('Recall',recall_score(y.values,ypredict_stress_global, average='weighted'))"
   ]
  },
  {
   "source": [
    "#### En utilisant les prédictions des diapos"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import LeaveOneGroupOut\n",
    "\n",
    "models_list = [\n",
    "                LogisticRegression(multi_class='multinomial', fit_intercept=True, random_state=42),\n",
    "                KNeighborsClassifier(),\n",
    "                RandomForestClassifier(random_state = 42, n_jobs=-1)\n",
    "                ]\n",
    "\n",
    "parameters_list = [\n",
    "                    {'C': [0.01, 0.05, 0.1, 0.5, 1, 2], 'class_weight' : [None, 'balanced']},\n",
    "                    {'n_neighbors': [4, 5, 6, 7, 8, 9, 10, 11, 12,  15, 20], 'weights' : ['uniform', 'distance'], 'p': [1, 2]},\n",
    "                    {'n_estimators': [50, 100, 150, 200], 'max_depth':[3, 4, 5, 6, 10, 15, 20], 'class_weight':[None,'balanced']}\n",
    "                    ]\n",
    "X = ypredict_stress_diapo\n",
    "y = df_annotations_stress.iloc[:,-1]\n",
    "groups = X.reset_index()['video_name']\n",
    "loo = LeaveOneGroupOut()\n",
    "cv_loo = loo.split(X, y, groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  45 out of  60 | elapsed:    0.2s remaining:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done  60 out of  60 | elapsed:    0.3s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "Best estimator LogisticRegression(C=0.05, multi_class='multinomial', random_state=42)\n",
      "Best results 0.3567460317460318\n",
      "Best params {'C': 0.05, 'class_weight': None}\n",
      "accuracy (mean, std) 0.4666666666666666 0.1247219128924647\n",
      "f1 (mean, std) 0.3567460317460318 0.16746972064173757\n",
      "balanced accuracy (mean, std) 0.4222222222222222 0.07535922203472521\n",
      "precision (mean, std) 0.3911111111111111 0.2365805790219695\n",
      "recall (mean, std) 0.4666666666666666 0.1247219128924647\n",
      "\n",
      "Fitting 5 folds for each of 44 candidates, totalling 220 fits\n",
      "[Parallel(n_jobs=-1)]: Done  56 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=-1)]: Done 220 out of 220 | elapsed:    0.6s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "Best estimator KNeighborsClassifier(n_neighbors=9, p=1)\n",
      "Best results 0.31873015873015875\n",
      "Best params {'n_neighbors': 9, 'p': 1, 'weights': 'uniform'}\n",
      "accuracy (mean, std) 0.39999999999999997 0.08164965809277261\n",
      "f1 (mean, std) 0.31873015873015875 0.11298376572637447\n",
      "balanced accuracy (mean, std) 0.38888888888888884 0.1217161238900369\n",
      "precision (mean, std) 0.32166666666666666 0.16763054614240208\n",
      "recall (mean, std) 0.39999999999999997 0.08164965809277261\n",
      "\n",
      "Fitting 5 folds for each of 56 candidates, totalling 280 fits\n",
      "[Parallel(n_jobs=-1)]: Done  52 tasks      | elapsed:    3.4s\n",
      "[Parallel(n_jobs=-1)]: Done 280 out of 280 | elapsed:   17.1s finished\n",
      "Best estimator RandomForestClassifier(max_depth=3, n_jobs=-1, random_state=42)\n",
      "Best results 0.15746031746031747\n",
      "Best params {'class_weight': None, 'max_depth': 3, 'n_estimators': 100}\n",
      "accuracy (mean, std) 0.2 0.12472191289246472\n",
      "f1 (mean, std) 0.15746031746031747 0.09621928428165781\n",
      "balanced accuracy (mean, std) 0.16666666666666666 0.1111111111111111\n",
      "precision (mean, std) 0.14333333333333334 0.09695359714832658\n",
      "recall (mean, std) 0.2 0.12472191289246472\n",
      "\n",
      "f1_score (weighted) 0.3854341736694678\n",
      "accuracy 0.4666666666666667\n"
     ]
    }
   ],
   "source": [
    "best_result, y_predict, y_predict_proba, result_list = runGridSearchClassifiers(X, y, 5, models_list, parameters_list, \n",
    "                                                                output_predict=True, n_jobs=-1, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'best_estimator': LogisticRegression(C=0.05, multi_class='multinomial', random_state=42),\n",
       " 'best_score': 0.3567460317460318,\n",
       " 'best_params': {'C': 0.05, 'class_weight': None},\n",
       " 'mean_test_f1_score': 0.3567460317460318,\n",
       " 'std_test_f1_score': 0.16746972064173757,\n",
       " 'mean_test_accuracy_score': 0.4666666666666666,\n",
       " 'std_test_accuracy_score': 0.1247219128924647,\n",
       " 'mean_test_balanced_accuracy_score': 0.4222222222222222,\n",
       " 'std_test_balanced_accuracy_score': 0.07535922203472521,\n",
       " 'mean_test_precision': 0.3911111111111111,\n",
       " 'std_test_precision': 0.2365805790219695,\n",
       " 'mean_test_recall': 0.4666666666666666,\n",
       " 'std_test_recall': 0.1247219128924647}"
      ]
     },
     "metadata": {},
     "execution_count": 38
    }
   ],
   "source": [
    "best_result"
   ]
  },
  {
   "source": [
    "## Aggregation all frames within the video to predict the global stress"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "#### All diapo"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import kurtosis, skew\n",
    "\n",
    "def percentil25(x): \n",
    "    return np.percentile(x, q=25)\n",
    "\n",
    "def percentil75(x): \n",
    "    return np.percentile(x, q=75)\n",
    "\n",
    "X = df_total.iloc[:,2:].groupby(['video_name']).agg({'mean','min','max', 'median', 'std', percentil25, percentil75, kurtosis, skew}).iloc[:,:-27]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df_total.iloc[:,2:].groupby(['video_name']).agg({'stress_global':'mean'}).iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import LeaveOneGroupOut\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "pca = PCA()\n",
    "pipe = Pipeline(steps=[('pca', pca), ('logistic', LogisticRegression(multi_class='multinomial', fit_intercept=True, random_state=42))])\n",
    "\n",
    "models_list = [\n",
    "                LogisticRegression(multi_class='multinomial', fit_intercept=True, random_state=42),\n",
    "                pipe,\n",
    "                KNeighborsClassifier(),\n",
    "                Pipeline(steps=[('pca', pca), ('knn', KNeighborsClassifier())]),\n",
    "                RandomForestClassifier(random_state = 42, n_jobs=-1)\n",
    "                ]\n",
    "\n",
    "parameters_list = [\n",
    "                    {'C': [0.01, 0.05, 0.1, 0.5, 1, 2, 3, 4 , 5, 10], 'class_weight' : [None, 'balanced']},\n",
    "                    {'pca__n_components': [1, 2, 3, 4],\n",
    "                        'logistic__C': [0.01, 0.05, 0.1, 0.5, 1, 2, 3, 4 , 5, 10], 'logistic__class_weight' : [None, 'balanced']},\n",
    "                    {'n_neighbors': [4, 5, 6, 7, 8, 9, 10, 11, 12,  15, 20], 'weights' : ['uniform', 'distance'], 'p': [1, 2]},\n",
    "                    {'pca__n_components': [1, 2, 3, 4],\n",
    "                        'knn__n_neighbors': [4, 5, 6, 7, 8, 9, 10, 11, 12,  15, 20], 'knn__weights' : ['uniform', 'distance'],                              'knn__p': [1, 2]},\n",
    "                    {'n_estimators': [50, 100, 150, 200], 'max_depth':[3, 4, 5, 6, 10, 15, 20], 'class_weight':[None,'balanced']}\n",
    "                    ]\n",
    "\n",
    "groups = X.reset_index()['video_name']\n",
    "loo = LeaveOneGroupOut()\n",
    "cv_loo = loo.split(X, y, groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    1.2s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    3.1s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "Best estimator LogisticRegression(C=1, class_weight='balanced', multi_class='multinomial',\n",
      "                   random_state=42)\n",
      "Best results 0.1422222222222222\n",
      "Best params {'C': 1, 'class_weight': 'balanced'}\n",
      "accuracy (mean, std) 0.16666666666666666 0.10540925533894598\n",
      "f1 (mean, std) 0.1422222222222222 0.1075886083280907\n",
      "balanced accuracy (mean, std) 0.14444444444444443 0.0753592220347252\n",
      "precision (mean, std) 0.1277777777777778 0.11055415967851333\n",
      "recall (mean, std) 0.16666666666666666 0.10540925533894598\n",
      "\n",
      "Fitting 5 folds for each of 80 candidates, totalling 400 fits\n",
      "[Parallel(n_jobs=-1)]: Done  52 tasks      | elapsed:    0.6s\n",
      "[Parallel(n_jobs=-1)]: Done 352 tasks      | elapsed:    3.1s\n",
      "[Parallel(n_jobs=-1)]: Done 400 out of 400 | elapsed:    3.5s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "Best estimator Pipeline(steps=[('pca', PCA(n_components=3)),\n",
      "                ('logistic',\n",
      "                 LogisticRegression(C=0.01, multi_class='multinomial',\n",
      "                                    random_state=42))])\n",
      "Best results 0.3514285714285714\n",
      "Best params {'logistic__C': 0.01, 'logistic__class_weight': None, 'pca__n_components': 3}\n",
      "accuracy (mean, std) 0.4 0.2260776661041756\n",
      "f1 (mean, std) 0.3514285714285714 0.25420148021245287\n",
      "balanced accuracy (mean, std) 0.4111111111111111 0.2398559238324767\n",
      "precision (mean, std) 0.36 0.3076273198225973\n",
      "recall (mean, std) 0.4 0.2260776661041756\n",
      "\n",
      "Fitting 5 folds for each of 44 candidates, totalling 220 fits\n",
      "[Parallel(n_jobs=-1)]: Done  56 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=-1)]: Done 220 out of 220 | elapsed:    1.1s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "Best estimator KNeighborsClassifier(n_neighbors=8, p=1)\n",
      "Best results 0.30190476190476195\n",
      "Best params {'n_neighbors': 8, 'p': 1, 'weights': 'uniform'}\n",
      "accuracy (mean, std) 0.39999999999999997 0.08164965809277261\n",
      "f1 (mean, std) 0.30190476190476195 0.1122274981360116\n",
      "balanced accuracy (mean, std) 0.3666666666666666 0.07535922203472521\n",
      "precision (mean, std) 0.2544444444444444 0.11687283370937517\n",
      "recall (mean, std) 0.39999999999999997 0.08164965809277261\n",
      "\n",
      "Fitting 5 folds for each of 176 candidates, totalling 880 fits\n",
      "[Parallel(n_jobs=-1)]: Done  56 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=-1)]: Done 880 out of 880 | elapsed:    4.3s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "Best estimator Pipeline(steps=[('pca', PCA(n_components=2)),\n",
      "                ('knn', KNeighborsClassifier(n_neighbors=9, p=1))])\n",
      "Best results 0.30190476190476195\n",
      "Best params {'knn__n_neighbors': 9, 'knn__p': 1, 'knn__weights': 'uniform', 'pca__n_components': 2}\n",
      "accuracy (mean, std) 0.39999999999999997 0.08164965809277261\n",
      "f1 (mean, std) 0.30190476190476195 0.1122274981360116\n",
      "balanced accuracy (mean, std) 0.3666666666666666 0.07535922203472521\n",
      "precision (mean, std) 0.2544444444444444 0.11687283370937517\n",
      "recall (mean, std) 0.39999999999999997 0.08164965809277261\n",
      "\n",
      "Fitting 5 folds for each of 56 candidates, totalling 280 fits\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    2.2s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:   11.7s\n",
      "[Parallel(n_jobs=-1)]: Done 280 out of 280 | elapsed:   18.3s finished\n",
      "Best estimator RandomForestClassifier(class_weight='balanced', max_depth=4, n_jobs=-1,\n",
      "                       random_state=42)\n",
      "Best results 0.26000000000000006\n",
      "Best params {'class_weight': 'balanced', 'max_depth': 4, 'n_estimators': 100}\n",
      "accuracy (mean, std) 0.26666666666666666 0.2\n",
      "f1 (mean, std) 0.26000000000000006 0.20044395171163884\n",
      "balanced accuracy (mean, std) 0.2333333333333333 0.18392161508052052\n",
      "precision (mean, std) 0.2722222222222222 0.227980939207591\n",
      "recall (mean, std) 0.26666666666666666 0.2\n",
      "\n",
      "f1_score (weighted) 0.3896296296296296\n",
      "accuracy 0.4\n"
     ]
    }
   ],
   "source": [
    "best_result, y_predict, y_predict_proba, result_list = runGridSearchClassifiers(X, y, 5, models_list, parameters_list, \n",
    "                                                                output_predict=True, n_jobs=-1, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'best_estimator': Pipeline(steps=[('pca', PCA(n_components=3)),\n",
       "                 ('logistic',\n",
       "                  LogisticRegression(C=0.01, multi_class='multinomial',\n",
       "                                     random_state=42))]),\n",
       " 'best_score': 0.3514285714285714,\n",
       " 'best_params': {'logistic__C': 0.01,\n",
       "  'logistic__class_weight': None,\n",
       "  'pca__n_components': 3},\n",
       " 'mean_test_f1_score': 0.3514285714285714,\n",
       " 'std_test_f1_score': 0.25420148021245287,\n",
       " 'mean_test_accuracy_score': 0.4,\n",
       " 'std_test_accuracy_score': 0.2260776661041756,\n",
       " 'mean_test_balanced_accuracy_score': 0.4111111111111111,\n",
       " 'std_test_balanced_accuracy_score': 0.2398559238324767,\n",
       " 'mean_test_precision': 0.36,\n",
       " 'std_test_precision': 0.3076273198225973,\n",
       " 'mean_test_recall': 0.4,\n",
       " 'std_test_recall': 0.2260776661041756}"
      ]
     },
     "metadata": {},
     "execution_count": 43
    }
   ],
   "source": [
    "best_result"
   ]
  },
  {
   "source": [
    "#### Audio diapo only"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import kurtosis, skew\n",
    "\n",
    "def percentil25(x): \n",
    "    return np.percentile(x, q=25)\n",
    "\n",
    "def percentil75(x): \n",
    "    return np.percentile(x, q=75)\n",
    "\n",
    "X_audio = df_total[df_total.diapo.isin([8,9,10,11,17])].iloc[:,2:].groupby(['video_name']).agg({'mean','min','max', 'median', 'std', percentil25, percentil75, kurtosis, skew}).iloc[:,:-27]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df_total.iloc[:,2:].groupby(['video_name']).agg({'stress_global':'mean'}).iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import LeaveOneGroupOut\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "pca = PCA()\n",
    "pipe = Pipeline(steps=[('pca', pca), ('logistic', LogisticRegression(multi_class='multinomial', fit_intercept=True, random_state=42))])\n",
    "\n",
    "models_list = [\n",
    "                LogisticRegression(multi_class='multinomial', fit_intercept=True, random_state=42),\n",
    "                pipe,\n",
    "                KNeighborsClassifier(),\n",
    "                Pipeline(steps=[('pca', pca), ('knn', KNeighborsClassifier())]),\n",
    "                RandomForestClassifier(random_state = 42, n_jobs=-1)\n",
    "                ]\n",
    "\n",
    "parameters_list = [\n",
    "                    {'C': [0.01, 0.05, 0.1, 0.5, 1, 2, 3, 4 , 5, 10], 'class_weight' : [None, 'balanced']},\n",
    "                    {'pca__n_components': [1, 2, 3, 4],\n",
    "                        'logistic__C': [0.01, 0.05, 0.1, 0.5, 1, 2, 3, 4 , 5, 10], 'logistic__class_weight' : [None, 'balanced']},\n",
    "                    {'n_neighbors': [4, 5, 6, 7, 8, 9, 10, 11, 12,  15, 20], 'weights' : ['uniform', 'distance'], 'p': [1, 2]},\n",
    "                    {'pca__n_components': [1, 2, 3, 4],\n",
    "                        'knn__n_neighbors': [4, 5, 6, 7, 8, 9, 10, 11, 12,  15, 20], 'knn__weights' : ['uniform', 'distance'],                              'knn__p': [1, 2]},\n",
    "                    {'n_estimators': [50, 100, 150, 200], 'max_depth':[3, 4, 5, 6, 10, 15, 20], 'class_weight':[None,'balanced']}\n",
    "                    ]\n",
    "X = X_audio\n",
    "groups = X.reset_index()['video_name']\n",
    "loo = LeaveOneGroupOut()\n",
    "cv_loo = loo.split(X, y, groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  52 tasks      | elapsed:    1.5s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    2.5s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "Best estimator LogisticRegression(C=0.01, class_weight='balanced', multi_class='multinomial',\n",
      "                   random_state=42)\n",
      "Best results 0.2633333333333333\n",
      "Best params {'C': 0.01, 'class_weight': 'balanced'}\n",
      "accuracy (mean, std) 0.26666666666666666 0.0816496580927726\n",
      "f1 (mean, std) 0.2633333333333333 0.07333333333333333\n",
      "balanced accuracy (mean, std) 0.2333333333333333 0.08888888888888889\n",
      "precision (mean, std) 0.3166666666666667 0.13788526273323173\n",
      "recall (mean, std) 0.26666666666666666 0.0816496580927726\n",
      "\n",
      "Fitting 5 folds for each of 80 candidates, totalling 400 fits\n",
      "[Parallel(n_jobs=-1)]: Done  56 tasks      | elapsed:    0.6s\n",
      "[Parallel(n_jobs=-1)]: Done 400 out of 400 | elapsed:    3.0s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "Best estimator Pipeline(steps=[('pca', PCA(n_components=3)),\n",
      "                ('logistic',\n",
      "                 LogisticRegression(C=0.01, multi_class='multinomial',\n",
      "                                    random_state=42))])\n",
      "Best results 0.256031746031746\n",
      "Best params {'logistic__C': 0.01, 'logistic__class_weight': None, 'pca__n_components': 3}\n",
      "accuracy (mean, std) 0.26666666666666666 0.1699673171197595\n",
      "f1 (mean, std) 0.256031746031746 0.18402953086060128\n",
      "balanced accuracy (mean, std) 0.2333333333333333 0.1625415426480866\n",
      "precision (mean, std) 0.3055555555555555 0.2515384760593727\n",
      "recall (mean, std) 0.26666666666666666 0.1699673171197595\n",
      "\n",
      "Fitting 5 folds for each of 44 candidates, totalling 220 fits\n",
      "[Parallel(n_jobs=-1)]: Done  56 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=-1)]: Done 220 out of 220 | elapsed:    1.0s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "Best estimator KNeighborsClassifier(n_neighbors=6, p=1)\n",
      "Best results 0.3273015873015873\n",
      "Best params {'n_neighbors': 6, 'p': 1, 'weights': 'uniform'}\n",
      "accuracy (mean, std) 0.4 0.1699673171197595\n",
      "f1 (mean, std) 0.3273015873015873 0.17764847905727496\n",
      "balanced accuracy (mean, std) 0.3666666666666666 0.17777777777777776\n",
      "precision (mean, std) 0.3088888888888889 0.21365716163061182\n",
      "recall (mean, std) 0.4 0.1699673171197595\n",
      "\n",
      "Fitting 5 folds for each of 176 candidates, totalling 880 fits\n",
      "[Parallel(n_jobs=-1)]: Done  56 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=-1)]: Done 880 out of 880 | elapsed:    4.3s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "Best estimator Pipeline(steps=[('pca', PCA(n_components=1)),\n",
      "                ('knn', KNeighborsClassifier(n_neighbors=11, p=1))])\n",
      "Best results 0.38126984126984126\n",
      "Best params {'knn__n_neighbors': 11, 'knn__p': 1, 'knn__weights': 'uniform', 'pca__n_components': 1}\n",
      "accuracy (mean, std) 0.4666666666666666 0.19436506316151006\n",
      "f1 (mean, std) 0.38126984126984126 0.203287171197036\n",
      "balanced accuracy (mean, std) 0.42222222222222217 0.14315665251916806\n",
      "precision (mean, std) 0.3472222222222222 0.1979836631245051\n",
      "recall (mean, std) 0.4666666666666666 0.19436506316151006\n",
      "\n",
      "Fitting 5 folds for each of 56 candidates, totalling 280 fits\n",
      "[Parallel(n_jobs=-1)]: Done  52 tasks      | elapsed:    3.8s\n",
      "[Parallel(n_jobs=-1)]: Done 216 tasks      | elapsed:   14.8s\n",
      "[Parallel(n_jobs=-1)]: Done 280 out of 280 | elapsed:   18.8s finished\n",
      "Best estimator RandomForestClassifier(class_weight='balanced', max_depth=4, n_estimators=150,\n",
      "                       n_jobs=-1, random_state=42)\n",
      "Best results 0.3622222222222223\n",
      "Best params {'class_weight': 'balanced', 'max_depth': 4, 'n_estimators': 150}\n",
      "accuracy (mean, std) 0.4 0.24944382578492946\n",
      "f1 (mean, std) 0.3622222222222223 0.2606355006470356\n",
      "balanced accuracy (mean, std) 0.38888888888888895 0.27888667551135854\n",
      "precision (mean, std) 0.35 0.28952920490656403\n",
      "recall (mean, std) 0.4 0.24944382578492946\n",
      "\n",
      "f1_score (weighted) 0.3916666666666667\n",
      "accuracy 0.4666666666666667\n"
     ]
    }
   ],
   "source": [
    "best_result, y_predict, y_predict_proba, result_list = runGridSearchClassifiers(X, y, 5, models_list, parameters_list, \n",
    "                                                                output_predict=True, n_jobs=-1, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'best_estimator': Pipeline(steps=[('pca', PCA(n_components=1)),\n",
       "                 ('knn', KNeighborsClassifier(n_neighbors=11, p=1))]),\n",
       " 'best_score': 0.38126984126984126,\n",
       " 'best_params': {'knn__n_neighbors': 11,\n",
       "  'knn__p': 1,\n",
       "  'knn__weights': 'uniform',\n",
       "  'pca__n_components': 1},\n",
       " 'mean_test_f1_score': 0.38126984126984126,\n",
       " 'std_test_f1_score': 0.203287171197036,\n",
       " 'mean_test_accuracy_score': 0.4666666666666666,\n",
       " 'std_test_accuracy_score': 0.19436506316151006,\n",
       " 'mean_test_balanced_accuracy_score': 0.42222222222222217,\n",
       " 'std_test_balanced_accuracy_score': 0.14315665251916806,\n",
       " 'mean_test_precision': 0.3472222222222222,\n",
       " 'std_test_precision': 0.1979836631245051,\n",
       " 'mean_test_recall': 0.4666666666666666,\n",
       " 'std_test_recall': 0.19436506316151006}"
      ]
     },
     "metadata": {},
     "execution_count": 48
    }
   ],
   "source": [
    "best_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}